name: Setup Dependabot

on:
  workflow_call:
    inputs:

      create_issue:
        required: false
        type: boolean
        default: true

      issue_title:
        required: false
        type: string
        default: 'Reporte Dependabot: ${date}'

      issue_labels:
        required: false
        type: string
        default: 'dependabot-report'

      close_dependabot_prs:
        required: false
        type: boolean
        default: true

      wait_minutes:
        required: false
        type: number
        default: 5

      create_missing_labels:
        required: false
        type: boolean
        default: false

      create_issue_if_empty:
        required: false
        type: boolean
        default: true

      upload_debug_artifact:
        required: false
        type: boolean
        default: true

      trigger_dependabot_now:
        required: false
        type: boolean
        default: false

      dependabot_config_path:
        required: false
        type: string
        default: '.github/dependabot.yml'

      dependabot_logins:
        required: false
        type: string
        default: 'dependabot,dependabot[bot],app/dependabot'

      poll_interval_seconds:
        required: false
        type: number
        default: 30

      dry_run_close:
        required: false
        type: boolean
        default: false

      skip_close_labels:
        required: false
        type: string
        default: ''

      max_prs_in_summary:
        required: false
        type: number
        default: 30

      generate_pdf_report:
        required: false
        type: boolean
        default: false

      pdf_report_name:
        required: false
        type: string
        default: 'dependabot-report.pdf'

      generate_html_report:
        required: false
        type: boolean
        default: true

      html_report_name:
        required: false
        type: string
        default: 'dependabot-report.html'
      fast_summary:
        required: false
        type: boolean
        default: true

      prs_state:
        required: false
        type: string
        default: 'open'

jobs:
  configure:
    name: Configuring
    runs-on: ubuntu-latest
    timeout-minutes: 45
    concurrency:
      group: dependabot-report
      cancel-in-progress: true
    permissions:
      contents: write
      issues: write
      pull-requests: write

    steps:
      - name: üöÄ Checkout Repository
        uses: actions/checkout@v4

      - name: üïí Marcar inicio
        if: false
        run: echo "skip"

      - name: üß™ Preparar logs de depuraci√≥n
        run: |
          mkdir -p docs
          printf "[START] Dependabot report debug at %s\n" "$(date -u +'%Y-%m-%d %H:%M:%SZ')" > docs/output.txt

      - name: ‚ö° Trigger Dependabot (opcional)
        if: ${{ inputs.trigger_dependabot_now }}
        env:
          GH_TOKEN: ${{ github.token }}
          CFG_PATH: ${{ inputs.dependabot_config_path }}
        run: |
          set -e
          if [ ! -f "$CFG_PATH" ]; then
            echo "::warning::No existe $CFG_PATH. No se puede forzar ejecuci√≥n"
            exit 0
          fi
          TS=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          echo "# trigger: $TS" >> "$CFG_PATH"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$CFG_PATH"
          if git diff --cached --quiet; then
            echo "Sin cambios en $CFG_PATH"
          else
            git commit -m "chore(dependabot): trigger run at $TS"
            git push || echo "::warning::No se pudo pushear cambios (verificar permisos)"
            echo "Triggered Dependabot via config change at $TS" >> docs/output.txt
          fi

      - name: üîç Validate Labels
        id: validate_labels
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          cat > /tmp/validate_labels.py << 'SCRIPT_EOF'
          import json, os, subprocess, sys
          from collections import defaultdict

          repo = os.getenv('GITHUB_REPOSITORY')

          try:
              result = subprocess.run(
                  ['gh', 'label', 'list', '--repo', repo, '--json', 'name,color,description', '--limit', '1000'],
                  capture_output=True, text=True, check=True
              )
              labels_data = json.loads(result.stdout)
              existing_labels = {label['name'].lower(): label for label in labels_data}
          except Exception as e:
              print(f"::error::No se pudieron obtener los labels: {e}")
              existing_labels = {}

          try:
              ecosystems = json.loads('''${{ inputs.ecosystems }}''')
          except json.JSONDecodeError as e:
              print(f"::error::Error al parsear ecosistemas: {e}")
              sys.exit(1)

          missing_by_ecosystem = defaultdict(list)
          valid_by_ecosystem = defaultdict(list)
          filtered_ecosystems = []
          all_missing = set()

          for eco in ecosystems:
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              valid_labels = []
              
              for label in labels:
                  if label.lower() in existing_labels:
                      valid_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      valid_labels.append(label)
                  else:
                      missing_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      all_missing.add(label)

              # Crear ecosistema filtrado con SOLO labels v√°lidos
              filtered_eco = eco.copy()
              filtered_eco['labels'] = ','.join(valid_labels)
              filtered_ecosystems.append(filtered_eco)

          # Generar outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"missing_labels={','.join(sorted(all_missing))}\n")
              f.write(f"missing_count={len(all_missing)}\n")
              f.write(f"valid_count={sum(len(v) for v in valid_by_ecosystem.values())}\n")
              f.write(f"has_missing={'true' if all_missing else 'false'}\n")
              
              # Exportar ecosistemas filtrados
              filtered_json = json.dumps(filtered_ecosystems)
              f.write(f"filtered_ecosystems<<EOF\n")
              f.write(f"{filtered_json}\n")
              f.write(f"EOF\n")

          # Guardar datos para el summary
          with open('/tmp/validation_data.json', 'w') as f:
              json.dump({
                  'missing_by_ecosystem': dict(missing_by_ecosystem),
                  'valid_by_ecosystem': dict(valid_by_ecosystem),
                  'existing_labels': existing_labels
              }, f)

          if all_missing:
              print(f"::warning title=Labels Faltantes::Se encontraron {len(all_missing)} labels sin configurar. Ser√°n omitidos del archivo generado.")
              for label in sorted(all_missing):
                  print(f"  ‚ö†Ô∏è {label}")
          else:
              print("::notice title=Validaci√≥n Exitosa::Todos los labels est√°n configurados correctamente")
          
          print(f"\nüìä Resumen:")
          print(f"  ‚úÖ Labels v√°lidos: {sum(len(v) for v in valid_by_ecosystem.values())}")
          print(f"  ‚ö†Ô∏è Labels faltantes: {len(all_missing)}")
          print(f"  üì¶ Ecosistemas: {len(ecosystems)}")
          SCRIPT_EOF

          python3 /tmp/validate_labels.py

      - name: üè∑Ô∏è Crear labels faltantes
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          MISSING="${{ steps.validate_labels.outputs.missing_labels }}"
          REPO="$GITHUB_REPOSITORY"
          IFS=',' read -ra LABELS <<< "$MISSING"
          for l in "${LABELS[@]}"; do
            [ -z "$l" ] && continue
            gh label create "$l" --repo "$REPO" --color 0366d6 --description "Auto-creado para Dependabot" || true
            echo "Creado label: $l"
          done

      - name: üè∑Ô∏è Crear labels del Issue faltantes
        if: ${{ inputs.issue_labels != '' && inputs.create_missing_labels }}
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
        run: |
          REPO="$GITHUB_REPOSITORY"
          EXISTING=$(gh label list --repo "$REPO" --json name --jq '.[].name')
          declare -A MAP
          for n in $EXISTING; do MAP[$n]=1; done
          IFS=',' read -ra LBS <<< "$ISSUE_LABELS"
          for l in "${LBS[@]}"; do
            NAME=$(echo "$l" | xargs)
            [ -z "$NAME" ] && continue
            if [ -z "${MAP[$NAME]}" ]; then
              gh label create "$NAME" --repo "$REPO" --color 6f42c1 --description "Auto-creado para reporte" || true
              echo "Creado label de Issue: $NAME"
            fi
          done

      - name: üìù Generate Dependabot Config
        if: false
        env:
          FILTERED_ECOSYSTEMS: ${{ steps.validate_labels.outputs.filtered_ecosystems }}
        run: |
          cat > /tmp/generate_config.py << 'SCRIPT_EOF'
          import json, os, sys

          try:
              ecosystems = json.loads(os.getenv('FILTERED_ECOSYSTEMS', '[]'))
          except json.JSONDecodeError as e:
              print(f"::error::JSON inv√°lido: {e}")
              sys.exit(1)

          if not ecosystems:
              print("::error::No hay ecosistemas para configurar")
              sys.exit(1)

          schedule = '${{ inputs.schedule }}'
          pr_limit = ${{ inputs.pr_limit }}
          target_branch = '${{ inputs.target_branch }}'

          config = {'version': 2, 'updates': []}

          for eco in ecosystems:
              update = {
                  'package-ecosystem': eco['ecosystem'],
                  'directory': eco['directory'],
                  'schedule': {'interval': schedule},
                  'open-pull-requests-limit': eco.get('pr_limit', pr_limit)
              }

              if target_branch:
                  update['target-branch'] = target_branch

              # Los labels ya est√°n filtrados (solo v√°lidos)
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              if labels:
                  update['labels'] = labels

              prefix = eco.get('prefix', '').strip()
              if prefix:
                  update['commit-message'] = {'prefix': prefix}

              config['updates'].append(update)

          import yaml
          os.makedirs('.github', exist_ok=True)

          with open('.github/dependabot.yml', 'w') as f:
            yaml.dump(config, f, sort_keys=False, default_flow_style=False, indent=2)

          print("‚úÖ Configuraci√≥n generada exitosamente (solo con labels v√°lidos)")

          with open('.github/dependabot.yml', 'r') as f:
              content = f.read()
              print("\nüìÑ Contenido generado:")
              print(content)
          SCRIPT_EOF

          python3 /tmp/generate_config.py

      - name: üíæ Commit Changes
        id: commit
        if: false
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          if git diff --quiet .github/dependabot.yml; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "üìå Sin cambios - La configuraci√≥n est√° actualizada"
          else
            git add .github/dependabot.yml
            git commit -m "chore: update dependabot configuration"
            git push
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "commit_sha=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
            echo "‚úÖ Cambios commiteados y pusheados"
          fi

      - name: üîÑ Detect Dependabot PRs
        id: detect_prs
        env:
          GH_TOKEN: ${{ github.token }}
          WAIT_MINUTES: ${{ inputs.wait_minutes }}
          POLL_INTERVAL: ${{ inputs.poll_interval_seconds }}
          DEP_LOGINS: ${{ inputs.dependabot_logins }}
          PRS_STATE: ${{ inputs.prs_state }}
        run: |
          cat > /tmp/detect_prs.py << 'SCRIPT_EOF'
          # Poll de PRs abiertos usando la API de GitHub v√≠a gh CLI.
          # Filtra por autores de Dependabot (varios formatos) y escribe logs de depuraci√≥n.
          import json, os, subprocess, time
          
          wait_minutes = int(os.getenv('WAIT_MINUTES', '10'))
          poll_interval = int(os.getenv('POLL_INTERVAL', '30'))
          repo = os.getenv('GITHUB_REPOSITORY')
          debug_path = os.path.join('docs','output.txt')
          dep_logins = [s.strip() for s in os.getenv('DEP_LOGINS','dependabot,dependabot[bot],app/dependabot').split(',') if s.strip()]
          
          def log(msg):
              try:
                  with open(debug_path,'a') as df:
                      df.write(msg + "\n")
              except Exception:
                  pass
          
          def list_prs_api():
            # Obtiene PRs abiertos y filtra por login de usuario
            try:
              state = os.getenv('PRS_STATE','open')
              path = f"repos/{repo}/pulls?state={state}&per_page=100"
              args = ['gh','api',path,'--method','GET']
              result = subprocess.run(args, capture_output=True, text=True)
              if result.returncode == 0 and result.stdout.strip():
                data = json.loads(result.stdout)
                filtered = []
                for pr in data:
                  login = (pr.get('user',{}) or {}).get('login','')
                  if login in dep_logins:
                    filtered.append({
                      'number': pr.get('number'),
                      'title': pr.get('title'),
                      'url': pr.get('html_url'),
                      'labels': pr.get('labels',[]),
                      'createdAt': pr.get('created_at',''),
                      'headRefName': (pr.get('head',{}) or {}).get('ref',''),
                      'state': pr.get('state','')
                    })
                return filtered
              log(f"list_prs_api non-0 returncode: {result.returncode} stderr={result.stderr.strip()}")
              return []
            except Exception as e:
              log(f"list_prs_api exception: {e}")
              return []
          
          prs = list_prs_api()
          log(f"Initial PRs count: {len(prs)}")
          if prs:
              for pr in prs:
                  log(f"PR #{pr['number']} - {pr['title']} - {pr['url']}")
          
          deadline = time.time() + wait_minutes*60
          while len(prs) == 0 and time.time() < deadline:
              time.sleep(poll_interval)
              prs = list_prs_api()
              log(f"Polling... PRs count: {len(prs)}")
          
          # Export outputs
          with open(os.environ['GITHUB_OUTPUT'],'a') as f:
              # Exporta resultados para usar en pasos posteriores
              f.write('prs_data<<EOF\n')
              f.write(json.dumps(prs))
              f.write('\nEOF\n')
              f.write(f"prs_count={len(prs)}\n")
          
          print(f"üìä PRs detectados: {len(prs)}")
          SCRIPT_EOF
          
          python3 /tmp/detect_prs.py

      - name: üßæ Crear Issue de Reporte
        id: create_issue
        if: ${{ inputs.create_issue && (steps.detect_prs.outputs.prs_count != '0' || inputs.create_issue_if_empty) }}
        env:
          GH_TOKEN: ${{ github.token }}
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          ISSUE_TITLE_TPL: ${{ inputs.issue_title }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          cat > /tmp/create_issue.py << 'SCRIPT_EOF'
          # Construye el cuerpo del Issue con tabla resumen y detalles.
          # Reutiliza el Issue si ya existe con el mismo t√≠tulo.
          import json, os, re, subprocess
          from datetime import datetime, timezone
          
          debug_path = os.path.join('docs','output.txt')
          
          def log(msg):
              try:
                  with open(debug_path,'a') as df:
                      df.write(msg + "\n")
              except Exception:
                  pass
          
          def pr_details(num, repo):
              # Recupera el cuerpo del PR para incluir un snippet en el Issue
              try:
                  r = subprocess.run(['gh','pr','view',str(num),'--repo',repo,'--json','body'], capture_output=True, text=True)
                  if r.returncode == 0:
                      data = json.loads(r.stdout)
                      return data.get('body','')
                  return ''
              except Exception:
                  return ''
          
          def parse_title(t):
              # Extrae paquete, versiones y directorio del t√≠tulo t√≠pico de Dependabot
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None
          
          def semver_tuple(s):
              # Convierte versi√≥n a tupla (major, minor, patch)
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          
          def update_type(f, t):
              # Determina tipo de actualizaci√≥n por comparaci√≥n sem√°ntica
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          
          def build_body(prs, date, repo):
            # Construye el contenido Markdown detallado del Issue
            lines = []
            run_id = os.getenv('RUN_ID','')
            server_url = os.getenv('SERVER_URL','https://github.com')
            if run_id:
                lines.append(f"**Descargar reportes (PDF/HTML):** {server_url}/{repo}/actions/runs/{run_id}\n\n")
            lines.append(f"### Reporte de actualizaciones ({date})\n")
            if prs:
                agg = {'major':0,'minor':0,'patch':0,'other':0}
                lines.append("\n| PR | Paquete | Desde | Hasta | Dir | Labels |\n")
                lines.append("|:--:|:-------|:-----:|:-----:|:---:|:------:|\n")
                for pr in prs:
                    num = pr.get('number')
                    url = pr.get('url')
                    title_pr = pr.get('title','')
                    meta = parse_title(title_pr) or {'name':'‚Äî','from':'‚Äî','to':'‚Äî','dir':''}
                    labels_pr = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or '‚Äî'
                    lines.append(f"| [#{num}]({url}) | {meta['name']} | {meta['from']} | {meta['to']} | {meta['dir']} | {labels_pr} |\n")
                    if meta['from'] != '‚Äî' and meta['to'] != '‚Äî':
                        agg[update_type(meta['from'], meta['to'])] += 1
                lines.append("\n#### Resumen por tipo\n")
                lines.append(f"- Major: {agg['major']}\n- Minor: {agg['minor']}\n- Patch: {agg['patch']}\n- Other: {agg['other']}\n")
                lines.append("\n#### Detalles\n")
                for pr in prs:
                    num = pr.get('number')
                    url = pr.get('url')
                    title_pr = pr.get('title','')
                    body = pr_details(num, repo)
                    snippet = (body or '').strip()
                    if len(snippet) > 1200:
                        snippet = snippet[:1200] + '‚Ä¶'
                    lines.append(f"- [#{num}]({url}) {title_pr}\n")
                    if snippet:
                        lines.append(f"  \n  {snippet}\n")
            else:
                lines.append("\nNo se encontraron PRs abiertos de Dependabot en este momento.\n")
            return ''.join(lines)

          def find_existing_issue(title, repo):
              # Busca un Issue abierto con t√≠tulo id√©ntico para evitar duplicados
              try:
                  r = subprocess.run(['gh','issue','list','--repo',repo,'--state','open','--limit','100','--json','number,title,url'], capture_output=True, text=True)
                  if r.returncode == 0 and r.stdout.strip():
                      items = json.loads(r.stdout)
                      for it in items:
                          if it.get('title','') == title:
                              return it.get('url','')
                  return ''
              except Exception:
                  return ''
          
          def main():
            # Orquesta la creaci√≥n o reutilizaci√≥n del Issue
            prs_raw = os.getenv('PRS_DATA','[]')
            prs = json.loads(prs_raw) if prs_raw.strip() else []
            date = datetime.now(timezone.utc).strftime('%Y-%m-%d')
            title_tpl = os.getenv('ISSUE_TITLE_TPL','Reporte Dependabot: ${date}')
            title = title_tpl.replace('${date}', date)
            labels = [l.strip() for l in os.getenv('ISSUE_LABELS','').split(',') if l.strip()]
            repo = os.getenv('GITHUB_REPOSITORY')
            existing = find_existing_issue(title, repo)
            if existing:
                with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                    f.write(f"issue_url={existing}\n")
                log(f"Issue existente reutilizado: {existing}")
                print(f"üßæ Issue reutilizado: {existing}")
                return
            body = build_body(prs, date, repo)
            cmd = ['gh','issue','create','--repo',repo,'--title',title,'--body',body]
            for l in labels:
                cmd += ['--label', l]
            result = subprocess.run(cmd, capture_output=True, text=True)
            url = ''
            if result.returncode == 0:
                for line in result.stdout.splitlines():
                    if line.strip().startswith('https://'):
                        url = line.strip()
                        break
            else:
                log(f"Fallo al crear issue con labels. stderr: {result.stderr.strip()}")
                result2 = subprocess.run(['gh','issue','create','--repo',repo,'--title',title,'--body',body], capture_output=True, text=True)
                if result2.returncode == 0:
                    for line in result2.stdout.splitlines():
                        if line.strip().startswith('https://'):
                            url = line.strip()
                            break
                else:
                    log(f"Intento sin labels tambi√©n fall√≥. stderr: {result2.stderr.strip()}")
            with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                f.write(f"issue_url={url}\n")
            log(f"Issue title: {title}")
            log(f"Issue created: {url if url else 'N/A'}")
            print(f"üßæ Issue creado: {url if url else 'N/A'}")
          
          if __name__ == '__main__':
              main()
          SCRIPT_EOF
          
          python3 /tmp/create_issue.py

      - name: üìÑ Generar PDF del reporte
        id: generate_pdf
        if: ${{ inputs.generate_pdf_report }}
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PDF_PATH: docs/${{ inputs.pdf_report_name }}
          REPO: ${{ github.repository }}
          GH_TOKEN: ${{ github.token }}
        run: |
          python3 -m pip install --user reportlab || true
          export PYTHONPATH="$(python3 -c 'import site; print(site.getusersitepackages())')${PYTHONPATH:+:$PYTHONPATH}"
          python3 - << 'PY'
          # Genera un PDF con √≠ndice y m√©tricas por tipo, directorio y ecosistema
          import json, os
          from datetime import datetime, timezone
          created = False
          try:
              from reportlab.lib.pagesizes import A4
              from reportlab.lib import colors
              from reportlab.lib.styles import getSampleStyleSheet
              from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
          except Exception as e:
              # Fallback: sin reportlab, evita fallo y marca no creado
              out = os.environ.get('GITHUB_OUTPUT')
              if out:
                  with open(out,'a') as f:
                      f.write('created=false\n')
              print(f"Reportlab no disponible: {e}. Saltando generaci√≥n de PDF.")
              raise SystemExit(0)
          try:
              prs = json.loads(os.getenv('PRS_DATA','[]'))
          except Exception:
              prs = []
          pdf_path = os.getenv('PDF_PATH','docs/dependabot-report.pdf')
          os.makedirs(os.path.dirname(pdf_path), exist_ok=True)
          styles = getSampleStyleSheet()
          doc = SimpleDocTemplate(pdf_path, pagesize=A4)
          flow = []
          title = Paragraph('Reporte de Dependabot', styles['Title'])
          flow.append(title)
          flow.append(Spacer(1,12))
          ts = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          flow.append(Paragraph(f'Generado: {ts}', styles['Normal']))
          flow.append(Spacer(1,12))

          import re
          def parse_title(t):
              # Extrae metadatos del t√≠tulo t√≠pico de Dependabot
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return {'name':'‚Äî','from':'','to':'','dir':''}
          def semver_tuple(s):
              nums = [int(x) for x in re.findall(r"\d+", s)[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n (major/minor/patch/other)
              if not f or not t:
                  return 'other'
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def directory_of(pr):
              # Detecta directorio desde el t√≠tulo o la rama de Dependabot
              meta = parse_title(pr.get('title',''))
              if meta.get('dir'):
                  return meta['dir']
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'
          def ecosystem_of(pr):
              # Extrae ecosistema desde la rama (npm_and_yarn ‚Üí npm, etc.)
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+1:
                          eco = parts[idx+1]
                          return 'npm' if eco == 'npm_and_yarn' else eco
                  except Exception:
                      pass
              return 'unknown'

          total_agg = {'major':0,'minor':0,'patch':0,'other':0}
          dir_agg = {}
          eco_agg = {}
          server_url = os.getenv('GITHUB_SERVER_URL','https://github.com')
          repo_url = os.getenv('GITHUB_REPOSITORY','')
          for pr in prs:
              meta = parse_title(pr.get('title',''))
              typ = update_type(meta.get('from',''), meta.get('to',''))
              total_agg[typ] = total_agg.get(typ,0)+1
              d = directory_of(pr)
              dir_agg.setdefault(d, {'major':0,'minor':0,'patch':0,'other':0})
              dir_agg[d][typ] += 1
              e = ecosystem_of(pr)
              eco_agg.setdefault(e, {'major':0,'minor':0,'patch':0,'other':0})
              eco_agg[e][typ] += 1

          flow.append(Paragraph('√çndice', styles['Heading2']))
          # Tabla de contenidos para navegaci√≥n r√°pida del documento
          flow.append(Paragraph('1. Resumen general', styles['Normal']))
          flow.append(Paragraph('2. M√©tricas por directorio', styles['Normal']))
          flow.append(Paragraph('3. M√©tricas por ecosistema', styles['Normal']))
          flow.append(Paragraph('4. Listado de PRs', styles['Normal']))
          flow.append(Spacer(1,12))

          flow.append(Paragraph('üìä Resumen general', styles['Heading2']))
          flow.append(Spacer(1,6))
          data_summary = [['Tipo','Cantidad'],['major',total_agg['major']],['minor',total_agg['minor']],['patch',total_agg['patch']],['other',total_agg['other']]]
          tbl_sum = Table(data_summary, repeatRows=1)
          tbl_sum.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_sum)
          flow.append(Spacer(1,6))
          flow.append(Paragraph("Tipos basados en <link href='https://semver.org/'>SemVer</link>: üî∫ major ‚Ä¢ üü° minor ‚Ä¢ üü¢ patch ‚Ä¢ üîπ other", styles['Italic']))
          flow.append(Spacer(1,12))

          flow.append(Paragraph('M√©tricas por directorio', styles['Heading2']))
          flow.append(Spacer(1,6))
          from reportlab.platypus import Paragraph
          data_dir = [['Directorio','major','minor','patch','other']]
          for d in sorted(dir_agg.keys()):
              if d and d.startswith('/'):
                  href = f"{server_url}/{repo_url}/tree/main" + ('' if d == '/' else d)
                  d_cell = Paragraph(f"<link href='{href}'>{d}</link>", styles['Normal'])
              else:
                  d_cell = Paragraph(d or '/', styles['Normal'])
              row = [d_cell, dir_agg[d]['major'], dir_agg[d]['minor'], dir_agg[d]['patch'], dir_agg[d]['other']]
              data_dir.append(row)
          tbl_dir = Table(data_dir, repeatRows=1)
          tbl_dir.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_dir)
          flow.append(Spacer(1,12))

          flow.append(Paragraph('M√©tricas por ecosistema', styles['Heading2']))
          flow.append(Spacer(1,6))
          data_eco = [['Ecosistema','major','minor','patch','other']]
          for e in sorted(eco_agg.keys()):
              row = [e, eco_agg[e]['major'], eco_agg[e]['minor'], eco_agg[e]['patch'], eco_agg[e]['other']]
              data_eco.append(row)
          tbl_eco = Table(data_eco, repeatRows=1)
          tbl_eco.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_eco)
          flow.append(Spacer(1,12))

          # Alertas de seguridad (Dependabot)
          alerts = []
          severity_agg = {}
          repo = os.getenv('REPO','')
          try:
              import json as _j
              r = os.popen(f"gh api repos/{repo}/dependabot/alerts?state=open&per_page=100").read()
              _tmp = _j.loads(r)
              alerts = _tmp if isinstance(_tmp, list) else []
          except Exception:
              alerts = []
          for a in alerts:
              if isinstance(a, dict):
                  s = (a.get('severity','') or 'unknown').lower()
                  severity_agg[s] = severity_agg.get(s,0)+1

          if alerts:
              flow.append(Paragraph('üõ°Ô∏è Alertas de Seguridad (abiertas)', styles['Heading2']))
              flow.append(Spacer(1,6))
              data_sec = [['Severidad','Cantidad']]
              for k in ['critical','high','moderate','low','unknown']:
                  if k in severity_agg:
                      data_sec.append([k, severity_agg[k]])
              tbl_sec = Table(data_sec, repeatRows=1)
              tbl_sec.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
              flow.append(tbl_sec)
              flow.append(Spacer(1,6))
              data_alerts = [['Paquete','Severidad','Ecosistema','Manifest']]
              for a in alerts[:20]:
                  if not isinstance(a, dict):
                      continue
                  dep = a.get('dependency') if isinstance(a.get('dependency'), dict) else {}
                  pkg_obj = dep.get('package') if isinstance(dep.get('package'), dict) else {}
                  pkg = pkg_obj.get('name') or '‚Äî'
                  sev = a.get('severity','') or 'unknown'
                  eco = pkg_obj.get('ecosystem') or '‚Äî'
                  manifest = a.get('manifest_path','') or '‚Äî'
                  data_alerts.append([pkg, sev, eco, manifest])
              tbl_alerts = Table(data_alerts, repeatRows=1)
              tbl_alerts.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
              flow.append(tbl_alerts)
              flow.append(Spacer(1,12))

          flow.append(Paragraph('Listado de PRs', styles['Heading2']))
          flow.append(Spacer(1,6))
          from urllib.parse import quote_plus
          data = [['PR','Paquete','Desde','Hasta','Dir','Estado','Labels','Creado']]
          for pr in prs:
              num = pr.get('number','')
              title = pr.get('title','')
              meta = parse_title(title)
              created = pr.get('createdAt','')
              try:
                  created_fmt = datetime.fromisoformat(created.replace('Z','+00:00')).strftime('%Y-%m-%d')
              except Exception:
                  created_fmt = 'N/A'
              labels_list = pr.get('labels',[])
              labels_html = ' '.join([f"<link href='{server_url}/{repo_url}/pulls?q=is%3Apr+label%3A{quote_plus(l.get('name',''))}+author%3Aapp%2Fdependabot'>{l.get('name','')}</link>" for l in labels_list if l.get('name','')]) or '‚Äî'
              state = pr.get('state','open')
              d = meta.get('dir') or directory_of(pr)
              typ = 'other'
              try:
                  if meta and meta.get('from') and meta.get('to'):
                      typ = update_type(meta.get('from',''), meta.get('to',''))
              except Exception:
                  typ = 'other'
              emoji = {'major':'üî∫','minor':'üü°','patch':'üü¢','other':'üîπ'}.get(typ,'üîπ')
              from_badge = Paragraph(f"‚Ü©Ô∏è {meta.get('from','')}", styles['Normal'])
              to_badge = Paragraph(f"{emoji} {meta.get('to','')}", styles['Normal'])
              dir_cell = Paragraph(f"<link href='{server_url}/{repo_url}/tree/main" + ('' if d == '/' else d) + f"'>{d}</link>", styles['Normal']) if (d and d.startswith('/')) else Paragraph(d or '/', styles['Normal'])
              labels_cell = Paragraph(labels_html, styles['Normal'])
              pr_cell = Paragraph(f"<link href='{server_url}/{repo_url}/pull/{num}'>#{num}</link>", styles['Normal'])
              data.append([pr_cell, meta.get('name','‚Äî'), from_badge, to_badge, dir_cell, state, labels_cell, created_fmt])
          table = Table(data, repeatRows=1)
          table.setStyle(TableStyle([
              ('BACKGROUND',(0,0),(-1,0),colors.lightgrey),
              ('TEXTCOLOR',(0,0),(-1,0),colors.black),
              ('GRID',(0,0),(-1,-1),0.5,colors.grey),
              ('FONTNAME',(0,0),(-1,0),'Helvetica-Bold'),
              ('ALIGN',(0,0),(-1,-1),'LEFT'),
              ('VALIGN',(0,0),(-1,-1),'MIDDLE'),
          ]))
          flow.append(table)
          doc.build(flow)
          created = True
          out = os.environ.get('GITHUB_OUTPUT')
          if out:
              with open(out,'a') as f:
                  f.write('created=true\n')
          print(f"PDF generado en {pdf_path}")
          PY

      - name: üßæ Generar HTML del reporte
        if: ${{ inputs.generate_html_report }}
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          GH_TOKEN: ${{ github.token }}
          HTML_PATH: docs/${{ inputs.html_report_name }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
        run: |
          python3 - << 'PY'
          # Genera un HTML navegable con √≠ndice y m√©tricas agregadas
          import json, os
          from datetime import datetime, timezone
          import re
          try:
              prs = json.loads(os.getenv('PRS_DATA','[]'))
          except Exception:
              prs = []
          html_path = os.getenv('HTML_PATH','docs/dependabot-report.html')
          os.makedirs(os.path.dirname(html_path), exist_ok=True)
          issue_url = os.getenv('ISSUE_URL','')
          def parse_title(t):
              # Extrae paquete, versiones y directorio del t√≠tulo
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return {'name':'‚Äî','from':'','to':'','dir':''}
          def semver_tuple(s):
              nums = [int(x) for x in re.findall(r"\d+", s)[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n
              if not f or not t:
                  return 'other'
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def directory_of(pr):
              # Obtiene directorio principal del cambio
              meta = parse_title(pr.get('title',''))
              if meta.get('dir'):
                  return meta['dir']
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'
          def sanitize_dir_path(s, eco_hint=''):
              try:
                  d = (s or '/').strip().replace('\\','/')
                  if not d:
                      d = '/'
                  if d == '/':
                      return '/'
                  eco = (eco_hint or '').lower()
                  eco = 'github-actions' if eco == 'github_actions' else eco
                  if d.startswith('/main/') or d == '/main':
                      return '/.github/workflows' if eco == 'github-actions' else '/'
                  if ' ' in d:
                      return '/.github/workflows' if eco == 'github-actions' else '/'
                  first = d.split('/')[1] if d.startswith('/') and len(d.split('/'))>1 else d.split('/')[0]
                  if eco == 'github-actions' and first in ['actions','appleboy','main']:
                      return '/.github/workflows'
                  if '/main' in d:
                      parts = [seg for seg in d.split('/') if seg and seg != 'main']
                      d = '/' + '/'.join(parts)
                      if d == '/':
                          return '/'
                  return d
              except Exception:
                  return '/'
          def ecosystem_of(pr):
              # Detecta ecosistema desde la rama
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+1:
                          eco = parts[idx+1]
                          return 'npm' if eco == 'npm_and_yarn' else eco
                  except Exception:
                      pass
              return 'unknown'
          total_agg = {'major':0,'minor':0,'patch':0,'other':0}
          dir_agg = {}
          eco_agg = {}
          rows = []
          for pr in prs:
              meta = parse_title(pr.get('title',''))
              typ = update_type(meta.get('from',''), meta.get('to',''))
              total_agg[typ] = total_agg.get(typ,0)+1
              e = ecosystem_of(pr)
              d_raw = directory_of(pr)
              d = sanitize_dir_path(d_raw, e)
              dir_agg.setdefault(d, {'major':0,'minor':0,'patch':0,'other':0})
              dir_agg[d][typ] += 1
              eco_agg.setdefault(e, {'major':0,'minor':0,'patch':0,'other':0})
              eco_agg[e][typ] += 1
              labels = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or '‚Äî'
              created = pr.get('createdAt','')
              try:
                  created_fmt = datetime.fromisoformat(created.replace('Z','+00:00')).strftime('%Y-%m-%d')
              except Exception:
                  created_fmt = 'N/A'
              rows.append({'num': pr.get('number',''), 'name': meta['name'], 'from': meta['from'], 'to': meta['to'], 'dir': d, 'eco': e, 'state': pr.get('state','open'), 'labels': labels, 'labels_list': pr.get('labels',[]), 'created': created_fmt, 'created_iso': created, 'url': pr.get('url','#')})
          ts = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          repo = os.getenv('GITHUB_REPOSITORY','')
          server_url = os.getenv('GITHUB_SERVER_URL','https://github.com')
          run_id = os.getenv('GITHUB_RUN_ID','') or os.getenv('RUN_ID','')
          run_link = f"{server_url}/{repo}/actions/runs/{run_id}" if run_id else ''
          owner = repo.split('/')[0] if '/' in (repo or '') else (repo or '')
          org_link = f"{server_url}/{owner}" if owner else ''
          html = []
          html.append('<!doctype html><html data-bs-theme="dark"><head><meta charset="utf-8"><title>Reporte Dependabot</title>')
          html.append('<meta name="viewport" content="width=device-width, initial-scale=1">')
          html.append('<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">')
          html.append('<style>body{padding-top:64px} .badge-ver{font-size:0.85rem} .section-card{border:1px solid var(--bs-border-color);border-radius:.75rem;padding:1rem;margin-bottom:1rem;background:var(--bs-tertiary-bg);transition:box-shadow .15s ease,transform .15s ease} .section-card:hover{box-shadow:0 .5rem 1rem rgba(0,0,0,.2);transform:translateY(-2px);border-color:var(--bs-primary)} .table-responsive{max-height:540px;overflow:auto} .table thead th{position:sticky;top:0;background:var(--bs-tertiary-bg);z-index:1} .table tbody tr{transition:background-color .15s ease,color .15s ease} .table tbody tr:hover{background-color:var(--bs-secondary-bg);color:var(--bs-body-color)} .table tbody tr:hover a{color:var(--bs-body-color);text-decoration:none} .list-group-item{transition:background-color .15s ease,color .15s ease} .list-group-item:hover{background-color:var(--bs-secondary-bg);color:var(--bs-body-color)} .kpi{border-radius:.75rem;padding:1rem;background:var(--bs-tertiary-bg);border:1px solid var(--bs-border-color);transition:box-shadow .15s ease,transform .15s ease,color .15s ease} .kpi:hover{box-shadow:0 .5rem 1rem rgba(0,0,0,.25);transform:translateY(-2px);color:var(--bs-body-color)} .kpi.kpi-primary{border-left:4px solid var(--bs-primary)} .kpi.kpi-warning{border-left:4px solid var(--bs-warning)} .kpi.kpi-success{border-left:4px solid var(--bs-success)} .kpi.kpi-danger{border-left:4px solid var(--bs-danger)} .navbar{border-bottom:0 !important;box-shadow:none !important} .navbar .nav-link{transition:color .2s ease,opacity .2s ease,text-shadow .15s ease} .navbar .nav-link:hover{color:var(--bs-primary);opacity:.95;text-shadow:0 0 2px rgba(255,255,255,.25)} .accordion-button{transition:background-color .15s ease,color .15s ease} .accordion-button:hover{background-color:var(--bs-secondary-bg);color:var(--bs-body-color)} a{transition:color .2s ease,text-shadow .15s ease} a:hover{color:var(--bs-primary);text-shadow:0 0 2px rgba(255,255,255,.2)}</style>')
          html.append('</head><body>')
          html.append(f'<nav class="navbar navbar-expand-md fixed-top bg-body-tertiary border-bottom"><div class="container"><a class="navbar-brand d-flex align-items-center" href="#"><img src="https://extranet.prb.com.mx/Prb1.2/images/logos/logo_PRB.svg" alt="PRB" height="24" class="me-2">PRB</a><button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#topNav" aria-controls="topNav" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="topNav"><ul class="navbar-nav ms-auto me-2"><li class="nav-item"><a class="nav-link" href="#listado">PRs</a></li><li class="nav-item"><a class="nav-link" href="#resumen">Resumen</a></li><li class="nav-item"><a class="nav-link" href="#dir">Directorios</a></li><li class="nav-item"><a class="nav-link" href="#dir-detalles">Detalles</a></li><li class="nav-item"><a class="nav-link" href="{server_url}/{repo}" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 16 16" fill="currentColor" class="me-1"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01 .37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33 .66 .07-.52 .28-.87 .51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87 .31-1.59 .82-2.15-.08-.2-.36-1.02 .08-2.12 0 0 .67-.21 2.2 .82 .64-.18 1.32-.27 2-.27s1.36 .09 2 .27c1.53-1.04 2.2-.82 2.2-.82 .44 1.1 .16 1.92 .08 2.12 .51 .56 .82 1.27 .82 2.15 0 3.07-1.87 3.75-3.65 3.95 .29 .25 .54 .73 .54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21 .15 .46 .55 .38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg><span class="ms-1"><code>{repo or "‚Äî"}</code></span></a></li></ul></div></div></nav>')
          html.append('<div class="container my-4">')
          if issue_url:
              html.append(f'<div class="alert alert-secondary py-2">üßæ Reporte consolidado: <a href="{issue_url}" target="_blank" rel="noopener" class="text-decoration-none">{issue_url}</a></div>')
          html.append(f'<h1 class="mb-3">Reporte Dependabot</h1><p class="text-muted">Generado: {ts} ‚Ä¢ Repositorio: <a href="{server_url}/{repo}" target="_blank" rel="noopener" class="text-decoration-none"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 16 16" fill="currentColor" class="me-1"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg><code>{repo or "‚Äî"}</code></a></p>')
          

          def current_state_for(pr):
              st = (pr.get('state','open') or '').lower()
              if st != 'closed':
                  return st
              num = pr.get('number')
              try:
                  r = os.popen(f"gh api repos/{repo}/pulls/{num}").read()
                  data = json.loads(r)
                  merged_at = data.get('merged_at')
                  return 'merged' if merged_at else 'closed'
              except Exception:
                  return 'closed'

          open_rows, merged_rows, closed_rows = [], [], []
          for r in rows:
              st = current_state_for(r)
              if st == 'open':
                  open_rows.append(r)
              elif st == 'merged':
                  merged_rows.append(r)
              elif st == 'closed':
                  closed_rows.append(r)

          html.append('<div class="row g-3 mb-2">')
          html.append(f'<div class="col-md-3"><div class="kpi kpi-primary"><div class="fw-bold">üì¶ PRs totales</div><div class="display-6">\n<a href="{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot" target="_blank" rel="noopener" class="text-primary text-decoration-none">{len(rows)}</a></div></div></div>')
          html.append(f'<div class="col-md-3"><div class="kpi kpi-warning"><div class="fw-bold">üîì Abiertos</div><div class="display-6">\n<a href="{server_url}/{repo}/pulls?q=is%3Apr+is%3Aopen+author%3Aapp%2Fdependabot" target="_blank" rel="noopener" class="text-warning text-decoration-none">{len(open_rows)}</a></div></div></div>')
          html.append(f'<div class="col-md-3"><div class="kpi kpi-success"><div class="fw-bold">‚úÖ Fusionados</div><div class="display-6">\n<a href="{server_url}/{repo}/pulls?q=is%3Apr+is%3Amerged+author%3Aapp%2Fdependabot" target="_blank" rel="noopener" class="text-success text-decoration-none">{len(merged_rows)}</a></div></div></div>')
          html.append(f'<div class="col-md-3"><div class="kpi kpi-danger"><div class="fw-bold">‚ùå Cerrados</div><div class="display-6">\n<a href="{server_url}/{repo}/pulls?q=is%3Apr+is%3Aclosed+author%3Aapp%2Fdependabot" target="_blank" rel="noopener" class="text-danger text-decoration-none">{len(closed_rows)}</a></div></div></div>')
          html.append('</div>')
          try:
              prio = []
              for r in open_rows:
                  typ = 'other'
                  try:
                      typ = update_type(r.get('from',''), r.get('to','')) if r.get('from') and r.get('to') else 'other'
                  except Exception:
                      typ = 'other'
                  age = age_days(r.get('created_iso',''))
                  rv = risk_level(typ, age, r.get('labels_list',[]))
                  prio.append({ 'r': r, 'age': (age if isinstance(age,int) else 0), 'risk': rv, 'riskw': (3 if rv=='critical' else 2 if rv=='high' else 1 if rv=='medium' else 0) })
              prio = sorted(prio, key=lambda x: (x['riskw'], x['age']), reverse=True)[:10]
              if prio:
                  html.append('<div class="row g-3 mt-2"><div class="col-12">')
                  html.append('<h2 id="prioridad" class="mb-2">PRs prioritarios</h2>')
                  html.append('<div class="table-responsive">')
                  html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>PR</th><th>Paquete</th><th>Tipo</th><th>Riesgo</th><th>Edad</th><th>Dir</th></tr></thead><tbody>')
                  for it in prio:
                      r = it['r']
                      typ = update_type(r.get('from',''), r.get('to','')) if r.get('from') and r.get('to') else 'other'
                      html.append(
                          f'<tr>'
                          f'<td><a href="{r["url"]}" target="_blank" rel="noopener">#{r["num"]}</a></td>'
                          f'<td>{r["name"]}</td>'
                          f'<td>{type_badges(typ)}</td>'
                          f'<td>{risk_badge(it["risk"])}</td>'
                          f'<td>{it["age"]} d</td>'
                          f'<td>{dir_cell_html(r.get("dir","/"))}</td>'
                          f'</tr>'
                      )
                  html.append('</tbody></table>')
                  html.append('</div>')
                  html.append('</div></div>')
          except Exception:
              pass
          html.append('<h2 id="listado" class="mt-4">PRs por estado</h2>')
          html.append('<div class="accordion" id="prAccordion">')

          from urllib.parse import quote_plus
          def badge_for(ver, typ, kind):
              emoji = {'major':'üî∫','minor':'üü°','patch':'üü¢','other':'üîπ'}.get(typ,'üîπ')
              color = {'major':'danger','minor':'warning','patch':'success','other':'secondary'}.get(typ,'secondary')
              if kind == 'from':
                  return f'<span class="badge text-bg-secondary badge-ver">‚Ü©Ô∏è {ver}</span>'
              return f'<span class="badge text-bg-{color} badge-ver">{emoji} {ver}</span>'

          def label_tags(labels):
              if not labels:
                  return '‚Äî'
              parts = []
              for l in labels:
                  name = l.get('name','')
                  if not name:
                      continue
                  color = l.get('color','0d6efd')
                  href = f"{server_url}/{repo}/pulls?q=is%3Apr+label%3A{quote_plus(name)}+author%3Aapp%2Fdependabot"
                  parts.append(f'<a href="{href}" target="_blank" rel="noopener" class="badge rounded-pill" style="background-color: #{color}; color: #fff;">{name}</a>')
              return ' '.join(parts) or '‚Äî'

          def dir_cell_html(d):
              if d and d.startswith('/'):
                  href = f'{server_url}/{repo}/tree/main' + ('' if d == '/' else d)
                  return f'<a href="{href}" target="_blank" rel="noopener"><code>{d}</code></a>'
              return f'<code>{d}</code>'

          def age_days(iso):
              try:
                  from datetime import datetime, timezone
                  dt = datetime.fromisoformat((iso or '').replace('Z','+00:00'))
                  now = datetime.now(timezone.utc)
                  return (now - dt).days
              except Exception:
                  return None

          def risk_level(typ, age, labels):
              base = {'major':3,'minor':2,'patch':1,'other':1}.get(typ,1)
              extra = 0
              if isinstance(age,int) and age >= 60:
                  extra = 2
              elif isinstance(age,int) and age >= 30:
                  extra = 1
              has_sec = any((l.get('name','').lower().find('sec') >= 0) for l in (labels or []))
              if has_sec:
                  extra += 1
              score = base + extra
              if score >= 5:
                  return 'critical'
              if score >= 4:
                  return 'high'
              if score >= 3:
                  return 'medium'
              return 'low'

          def risk_badge(level):
              if level == 'critical':
                  return '<span class="badge text-bg-danger">üî• Cr√≠tico</span>'
              if level == 'high':
                  return '<span class="badge text-bg-warning">‚ö†Ô∏è Alto</span>'
              if level == 'medium':
                  return '<span class="badge text-bg-info">‚ÑπÔ∏è Medio</span>'
              return '<span class="badge text-bg-secondary">‚úÖ Bajo</span>'

          def render_rows(items):
              html.append('<div class="table-responsive">')
              html.append('<table class="table table-striped table-bordered table-sm mb-2 pr-table"><thead><tr><th data-sort="num">PR</th><th data-sort="name">Paquete</th><th data-sort="from">Desde</th><th data-sort="to">Hasta</th><th data-sort="dir">Dir</th><th data-sort="eco">Eco</th><th data-sort="risk">Riesgo</th><th data-sort="state">Estado</th><th data-sort="labels">Labels</th><th data-sort="created">Creado</th><th data-sort="age">Edad</th></tr></thead><tbody>')
              for r in items:
                  st = current_state_for(r)
                  typ = 'other'
                  try:
                      typ = update_type(r.get('from',''), r.get('to','')) if r.get('from') and r.get('to') else 'other'
                  except Exception:
                      typ = 'other'
                  age = age_days(r.get('created_iso',''))
                  labels_html = label_tags(r.get('labels_list',[])) if r.get('labels_list') is not None else r.get('labels','‚Äî')
                  risklev = risk_level(typ, age, r.get('labels_list',[]))
                  html.append(
                      f'<tr data-num="{r["num"]}" data-name="{r["name"]}" data-from="{r.get("from","")}" data-to="{r.get("to","")}" data-dir="{r.get("dir","/")}" data-eco="{r.get("eco","unknown")}" data-type="{typ}" data-risk="{risklev}" data-state="{st}" data-created="{r["created"]}" data-age="{(age if isinstance(age,int) else 0)}">' 
                        f'<td><a href="{r["url"]}" target="_blank" rel="noopener">#{r["num"]}</a></td>'
                        f'<td>{r["name"]}</td>'
                        f'<td>{badge_for(r.get("from",""), typ, "from")}</td>'
                        f'<td>{badge_for(r.get("to",""), typ, "to")}</td>'
                        f'<td>{dir_cell_html(r.get("dir","/"))}</td>'
                        f'<td><code>{r.get("eco","unknown")}</code></td>'
                        f'<td>{risk_badge(risklev)}</td>'
                        f'<td>{st}</td>'
                        f'<td>{labels_html}</td>'
                        f'<td>{r["created"]}</td>'
                        f'<td>' + ((str(age)+' d') if isinstance(age,int) else 'N/A') + '</td>'
                        f'</tr>'
                  )
              html.append('</tbody></table>')
              html.append('</div>')
              try:
                  open_pkg_names = { r.get('name','') for r in open_rows }
                  fixable_no_pr = []
                  for a in alerts:
                      if not isinstance(a, dict):
                          continue
                      dep = a.get('dependency') if isinstance(a.get('dependency'), dict) else {}
                      pkg_obj = dep.get('package') if isinstance(dep.get('package'), dict) else {}
                      name = pkg_obj.get('name') or ''
                      fx = a.get('fixed_version') or ''
                      if fx and name and name not in open_pkg_names:
                          fixable_no_pr.append({'name':name,'fix':fx,'manifest':a.get('manifest_path','') or '‚Äî'})
                  if fixable_no_pr:
                      html.append('<div class="mt-3"><div class="section-card"><h5 class="mb-2">Fix disponible sin PR</h5>')
                      html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Paquete</th><th>Fix</th><th>Manifest</th></tr></thead><tbody>')
                      for it in fixable_no_pr[:10]:
                          man = it['manifest']
                          man_ref = f'<a href="{server_url}/{repo}/blob/main/{man}" target="_blank" rel="noopener"><code>{man}</code></a>' if man != '‚Äî' else '<code>‚Äî</code>'
                          html.append(f'<tr><td>{it["name"]}</td><td><code>{it["fix"]}</code></td><td>{man_ref}</td></tr>')
                      html.append('</tbody></table></div></div>')
              except Exception:
                  pass

          html.append('<div class="accordion-item">')
          html.append('<h2 class="accordion-header" id="headingOpen">')
          html.append(f'<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOpen" aria-expanded="true" aria-controls="collapseOpen">PRs Abiertos ({len(open_rows)})</button>')
          html.append('</h2>')
          html.append('<div id="collapseOpen" class="accordion-collapse collapse show" aria-labelledby="headingOpen" data-bs-parent="#prAccordion"><div class="accordion-body">')
          render_rows(open_rows)
          html.append('</div></div></div>')

          html.append('<div class="accordion-item">')
          html.append('<h2 class="accordion-header" id="headingMerged">')
          html.append(f'<button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseMerged" aria-expanded="false" aria-controls="collapseMerged">PRs Fusionados ({len(merged_rows)})</button>')
          html.append('</h2>')
          html.append('<div id="collapseMerged" class="accordion-collapse collapse" aria-labelledby="headingMerged" data-bs-parent="#prAccordion"><div class="accordion-body">')
          render_rows(merged_rows)
          html.append('</div></div></div>')

          html.append('<div class="accordion-item">')
          html.append('<h2 class="accordion-header" id="headingClosed">')
          html.append(f'<button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseClosed" aria-expanded="false" aria-controls="collapseClosed">PRs Cerrados ({len(closed_rows)})</button>')
          html.append('</h2>')
          html.append('<div id="collapseClosed" class="accordion-collapse collapse" aria-labelledby="headingClosed" data-bs-parent="#prAccordion"><div class="accordion-body">')
          render_rows(closed_rows)
          html.append('</div></div></div>')

          html.append('</div>')
          
          
          # Resumen general y m√©tricas (ahora debajo de KPIs y PRs)
          html.append('<h2 id="resumen" class="mt-4">üìä Resumen general</h2>')
          html.append('<div class="row g-3 mb-2">')
          html.append('<div class="col-md-6">')
          html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Tipo</th><th>Cantidad</th></tr></thead><tbody>')
          for k in ['major','minor','patch','other']:
              html.append(f'<tr><td>{k}</td><td>{total_agg[k]}</td></tr>')
          html.append('</tbody></table>')
          html.append('<div class="alert alert-info" role="alert">üîé Tipos basados en <a href="https://semver.org/" target="_blank" rel="noopener">SemVer</a>: üî∫ major ‚Ä¢ üü° minor ‚Ä¢ üü¢ patch ‚Ä¢ üîπ other</div>')
          html.append('</div>')
          html.append('<div class="col-md-6"><div class="section-card">')
          html.append('<p>üìÅ Rutas de repositorio:</p><ul class="list-group">')
          for d in sorted(dir_agg.keys()):
              if d and d.startswith('/'):
                  href = f'{server_url}/{repo}/tree/main' + ('' if d == '/' else d)
                  html.append(f'<li class="list-group-item"><a href="{href}" target="_blank" rel="noopener"><code>{d}</code></a></li>')
              else:
                  html.append(f'<li class="list-group-item"><code>{d}</code></li>')
          html.append('</ul></div></div>')
          html.append('</div>')
          html.append('<div class="row g-3 mt-2">')
          html.append('<div class="col-md-6">')
          html.append('<h2 id="dir" class="mb-2">M√©tricas por directorio</h2>')
          html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Directorio</th><th>major</th><th>minor</th><th>patch</th><th>other</th></tr></thead><tbody>')
          for d in sorted(dir_agg.keys()):
              v = dir_agg[d]
              if d and d.startswith('/'):
                  href = f'{server_url}/{repo}/tree/main' + ('' if d == '/' else d)
                  cell = f'<a href="{href}" target="_blank" rel="noopener"><code>{d}</code></a>'
              else:
                  cell = f'<code>{d}</code>'
              html.append(f'<tr><td>{cell}</td><td>{v["major"]}</td><td>{v["minor"]}</td><td>{v["patch"]}</td><td>{v["other"]}</td></tr>')
          html.append('</tbody></table>')
          html.append('</div>')
          html.append('<div class="col-md-6">')
          html.append('<h2 id="eco" class="mb-2">M√©tricas por ecosistema</h2>')
          html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Ecosistema</th><th>major</th><th>minor</th><th>patch</th><th>other</th></tr></thead><tbody>')
          for e in sorted(eco_agg.keys()):
              v = eco_agg[e]
              html.append(f'<tr><td><code>{e}</code></td><td>{v["major"]}</td><td>{v["minor"]}</td><td>{v["patch"]}</td><td>{v["other"]}</td></tr>')
          html.append('</tbody></table>')
          html.append('</div>')
          html.append('</div>')

          html.append('<h2 id="dir-detalles" class="mt-4">üìÅ Detalles por directorio</h2>')
          def type_badges(t):
              base = '<span class="badge text-bg-primary me-1">update</span>'
              color = {'major':'danger','minor':'warning','patch':'success','other':'secondary'}.get(t,'secondary')
              return base + f'<span class="badge text-bg-{color}">{t}</span>'

          dir_groups = {}
          for r in rows:
              d = r.get('dir','/')
              dir_groups.setdefault(d, []).append(r)

          html.append('<div class="accordion" id="dirDetails">')
          for idx, d in enumerate(sorted(dir_groups.keys())):
              items = dir_groups[d]
              safe_dir = d if d else '/'
              head_id = f'head-{idx}'
              col_id = f'col-{idx}'
              html.append('<div class="accordion-item">')
              html.append(f'<h2 class="accordion-header" id="{head_id}">')
              html.append(f'<button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#{col_id}" aria-expanded="false" aria-controls="{col_id}"><span class="me-2"><code>{safe_dir}</code></span>({len(items)})</button>')
              html.append('</h2>')
              html.append(f'<div id="{col_id}" class="accordion-collapse collapse" aria-labelledby="{head_id}" data-bs-parent="#dirDetails"><div class="accordion-body">')
              html.append('<div class="table-responsive">')
              html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th data-sort="num">PR</th><th data-sort="name">Paquete</th><th data-sort="type">Tipo</th><th data-sort="created">Edad</th></tr></thead><tbody>')
              for r in items:
                  typ = 'other'
                  try:
                      typ = update_type(r.get('from',''), r.get('to','')) if r.get('from') and r.get('to') else 'other'
                  except Exception:
                      typ = 'other'
                  age = age_days(r.get('created_iso',''))
                  age_disp = (str(age)+' d') if isinstance(age,int) else 'N/A'
                  html.append(
                      f'<tr data-num="{r["num"]}" data-name="{r["name"]}" data-type="{typ}" data-dir="{safe_dir}" data-eco="{r.get("eco","unknown")}" data-state="{r.get("state","open").lower()}" data-created="{r["created"]}">' 
                      f'<td><a href="{r["url"]}" target="_blank" rel="noopener">#{r["num"]}</a></td>'
                      f'<td>{r["name"]}</td>'
                      f'<td>{type_badges(typ)}</td>'
                      f'<td>{age_disp}</td>'
                      f'</tr>'
                  )
              html.append('</tbody></table>')
              html.append('</div>')
              html.append('</div></div>')
              html.append('</div>')
          html.append('</div>')

          html.append('<h2 class="mt-4">üõ°Ô∏è Alertas de Seguridad</h2>')
          try:
              import json as _j
              r = os.popen(f"gh api repos/{repo}/dependabot/alerts?state=open&per_page=100").read()
              _tmp = _j.loads(r)
              alerts = _tmp if isinstance(_tmp, list) else []
          except Exception:
              alerts = []
          sev_agg = {}
          pkg_stats = {}
          for a in alerts:
              if isinstance(a, dict):
                  s = (a.get('severity','') or 'unknown').lower()
                  sev_agg[s] = sev_agg.get(s,0)+1
                  dep = a.get('dependency') if isinstance(a.get('dependency'), dict) else {}
                  pkg_obj = dep.get('package') if isinstance(dep.get('package'), dict) else {}
                  name = pkg_obj.get('name') or '‚Äî'
                  fx = a.get('fixed_version') or ''
                  ps = pkg_stats.get(name, {'count':0,'fix':'‚Äî'})
                  ps['count'] += 1
                  if fx:
                      ps['fix'] = '‚úÖ'
                  pkg_stats[name] = ps
          dir_pr_counts = {}
          for r in rows:
              d = r.get('dir','/') or '/'
              dir_pr_counts[d] = dir_pr_counts.get(d,0)+1
          alerts_dir_counts = {}
          for a in alerts:
              mp = (a.get('manifest_path','') or '').strip()
              dep = a.get('dependency') if isinstance(a.get('dependency'), dict) else {}
              pkg_obj = dep.get('package') if isinstance(dep.get('package'), dict) else {}
              eco_hint = (pkg_obj.get('ecosystem') or '').lower()
              d = '/'
              try:
                  if mp and '/' in mp:
                      parts = mp.split('/')
                      raw = '/' + '/'.join(parts[:-1])
                      d = sanitize_dir_path(raw, eco_hint)
                  elif mp:
                      d = sanitize_dir_path('/', eco_hint)
              except Exception:
                  d = '/'
              alerts_dir_counts[d] = alerts_dir_counts.get(d,0)+1
          if alerts:
              html.append('<div class="row g-3 mt-3">')
              html.append('<div class="col-md-4"><div class="section-card"><h5 class="mb-2">Resumen por severidad</h5>')
              html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Severidad</th><th>Cantidad</th></tr></thead><tbody>')
              for k in ['critical','high','moderate','low','unknown']:
                  if k in sev_agg:
                      html.append(f'<tr><td>{k}</td><td>{sev_agg[k]}</td></tr>')
              html.append('</tbody></table></div></div>')
              html.append('<div class="col-md-4"><div class="section-card"><h5 class="mb-2">Paquetes m√°s afectados</h5>')
              html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Paquete</th><th>Cantidad</th><th>Fix</th></tr></thead><tbody>')
              for name, ps in sorted(pkg_stats.items(), key=lambda kv: kv[1]['count'], reverse=True)[:10]:
                  html.append(f'<tr><td>{name}</td><td>{ps["count"]}</td><td>{ps["fix"]}</td></tr>')
              html.append('</tbody></table></div></div>')
              html.append('<div class="col-md-4"><div class="section-card"><h5 class="mb-2">Cobertura por directorio</h5>')
              html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Directorio</th><th>PRs</th><th>Alertas</th><th>Densidad</th></tr></thead><tbody>')
              for d in sorted(set(list(dir_pr_counts.keys()) + list(alerts_dir_counts.keys()))):
                  prs_c = dir_pr_counts.get(d,0)
                  alt_c = alerts_dir_counts.get(d,0)
                  dens = f"{(alt_c / prs_c):.2f}" if prs_c > 0 else ('‚àû' if alt_c > 0 else '0')
                  cell = f'<a href="{server_url}/{repo}/tree/main' + ('' if d == '/' else d) + f'" target="_blank" rel="noopener"><code>{d}</code></a>' if (d and d.startswith('/')) else f'<code>{d}</code>'
                  html.append(f'<tr><td>{cell}</td><td>{prs_c}</td><td>{alt_c}</td><td>{dens}</td></tr>')
              html.append('</tbody></table></div></div>')
              html.append('</div>')
              html.append('<div class="table-responsive">')
              html.append('<table class="table table-striped table-bordered table-sm mb-2"><thead><tr><th>Paquete</th><th>Severidad</th><th>CVSS</th><th>Ecosistema</th><th>Manifest</th><th>GHSA</th><th>CVE</th><th>Resumen</th><th>Rango</th><th>Fix</th></tr></thead><tbody>')
              for a in alerts[:50]:
                  if not isinstance(a, dict):
                      continue
                  dep = a.get('dependency') if isinstance(a.get('dependency'), dict) else {}
                  pkg_obj = dep.get('package') if isinstance(dep.get('package'), dict) else {}
                  pkg = pkg_obj.get('name') or '‚Äî'
                  sev = a.get('severity','') or 'unknown'
                  eco = pkg_obj.get('ecosystem') or '‚Äî'
                  manifest = a.get('manifest_path','') or '‚Äî'
                  adv = a.get('security_advisory') if isinstance(a.get('security_advisory'), dict) else {}
                  ghsa = adv.get('ghsa_id') or '‚Äî'
                  cve = adv.get('cve_id') or ''
                  cvss_obj = adv.get('cvss') if isinstance(adv.get('cvss'), dict) else {}
                  cvss = cvss_obj.get('score') if isinstance(cvss_obj.get('score'), (int,float)) else '‚Äî'
                  summary = adv.get('summary') or '‚Äî'
                  rng = a.get('vulnerable_version_range') or a.get('vulnerable_requirements') or '‚Äî'
                  fix = a.get('fixed_version') or '‚Äî'
                  ghsa_ref = f'<a href="https://github.com/advisories/{ghsa}" target="_blank" rel="noopener">{ghsa}</a>' if ghsa != '‚Äî' else '‚Äî'
                  cve_ref = f'<a href="https://nvd.nist.gov/vuln/detail/{cve}" target="_blank" rel="noopener">{cve}</a>' if cve else '‚Äî'
                  if manifest != '‚Äî' and isinstance(manifest,str):
                      man_ref = f'<a href="{server_url}/{repo}/blob/main/{manifest}" target="_blank" rel="noopener"><code>{manifest}</code></a>'
                  else:
                      man_ref = f'<code>{manifest}</code>'
                  html.append(f'<tr><td>{pkg}</td><td>{sev}</td><td>{cvss}</td><td>{eco}</td><td>{man_ref}</td><td>{ghsa_ref}</td><td>{cve_ref}</td><td>{summary}</td><td><code>{rng}</code></td><td><code>{fix}</code></td></tr>')
              html.append('</tbody></table>')
              html.append('</div>')
          else:
              html.append('<div class="alert alert-success" role="alert">No se detectaron alertas abiertas de Dependabot o no hay permisos para leerlas.</div>')
          html.append('<div class="alert alert-info mt-4"><h4 class="mb-2">Gu√≠a para empezar</h4><ol class="mb-0"><li>Revisa el <b>Resumen por severidad</b> para identificar alertas cr√≠ticas.</li><li>Verifica los <b>Paquetes m√°s afectados</b> para priorizar fixes.</li><li>Analiza la <b>Cobertura por directorio</b> para detectar rutas con alta densidad.</li><li>Consulta los PRs abiertos y el <b>Reporte consolidado</b> para planificar acciones.</li></ol></div>')
          html.append('<div class="section-card"><h4 class="mb-2">Recomendaciones de remediaci√≥n</h4><ul class="mb-0"><li>Prioriza <b>critical/high</b> y aplica versiones seguras indicadas en <b>Fix</b> del detalle de alertas.</li><li>Para <b>github_actions</b>, actualiza el tag en <code>/.github/workflows</code> y verifica permisos m√≠nimos en cada job.</li><li>En <b>pip/npm</b>, actualiza el manifiesto (<code>requirements.txt</code>, <code>package.json</code>) y genera lockfiles limpios.</li><li>Valida compatibilidad en staging y habilita <b>automerge</b> s√≥lo para <b>patch/minor</b> con checks verdes.</li><li>Documenta paquetes sin fix disponible y da seguimiento con los mantenedores.</li></ul></div>')
          html.append('</div>')

          html.append('<footer class="bg-body-tertiary border-top py-3 mt-4">')
          html.append('<div class="container d-flex flex-wrap align-items-center justify-content-between">')
          html.append('<div class="d-flex align-items-center mb-2 mb-md-0"><img src="https://extranet.prb.com.mx/Prb1.2/images/logos/logo_PRB.svg" alt="PRB" height="24" class="me-2"><strong>PRB</strong></div>')
          html.append('<div class="small">')
          if issue_url:
              html.append(f'üßæ <a href="{issue_url}" target="_blank" rel="noopener" class="text-decoration-none">Issue del reporte</a> ‚Ä¢ ')
          html.append(f'üì¶ <a href="{server_url}/{repo}" target="_blank" rel="noopener" class="text-decoration-none">Repositorio</a> ‚Ä¢ ')
          if org_link:
              html.append(f'üè¢ <a href="{org_link}" target="_blank" rel="noopener" class="text-decoration-none">Organizaci√≥n</a> ‚Ä¢ ')
          if run_link:
              html.append(f'‚öôÔ∏è <a href="{run_link}" target="_blank" rel="noopener" class="text-decoration-none">GitHub Actions (artefactos PDF/HTML)</a> ‚Ä¢ ')
          html.append(f'üïí Generado: {ts}')
          html.append('</div>')
          html.append('<div class="w-100 mt-2 small text-muted">‚ù§Ô∏èüöÄ Creado con amor por el equipo de DevOps</div>')
          html.append('</div>')
          html.append('</footer>')
          
          html.append('<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>')
          html.append('<script>\n' 
            'document.querySelectorAll("table thead th[data-sort]").forEach(th=>{th.style.cursor="pointer";th.addEventListener("click",()=>{const key=th.dataset.sort;const idx=th.cellIndex;const table=th.closest("table");const rows=[...table.tBodies[0].rows];const asc=th.dataset.order!="desc";function val(row){const attr=row.getAttribute("data-"+key);if(attr) return attr;return row.cells[idx].innerText.trim();} rows.sort((a,b)=>{let va=val(a), vb=val(b); if(key==="num"){va=parseInt(String(va).replace(/[^0-9]/g,''))||0; vb=parseInt(String(vb).replace(/[^0-9]/g,''))||0; return asc?va-vb:vb-va;} if(key==="created"){const da=Date.parse(va)||0, db=Date.parse(vb)||0; return asc?da-db:db-da;} if(key==="age"){va=parseInt(va)||0; vb=parseInt(vb)||0; return asc?va-vb:vb-va;} return asc?String(va).localeCompare(String(vb)):String(vb).localeCompare(String(va));});rows.forEach(r=>table.tBodies[0].appendChild(r));th.dataset.order=asc?"desc":"asc";});});\n' 
            ''
            ''
            '// charts removed\n' 
            'function initCharts(){try{const ct=document.getElementById("chartTypes");const ce=document.getElementById("chartEcos");if(ct){chartTypes=new Chart(ct,{type:"bar",data:{labels:["major","minor","patch","other"],datasets:[{label:"Tipos",data:[' + ','.join(str(total_agg[k]) for k in ['major','minor','patch','other']) + '],backgroundColor:["#dc3545","#ffc107","#198754","#6c757d"]}]},options:{responsive:true,plugins:{legend:{display:false}},scales:{x:{ticks:{color:cc.text},grid:{color:cc.grid}},y:{ticks:{color:cc.text},grid:{color:cc.grid}}}});} if(ce){chartEcos=new Chart(ce,{type:"doughnut",data:{labels:' + json.dumps(sorted(list(eco_agg.keys()))) + ',datasets:[{data:' + json.dumps([eco_agg[e]['major']+eco_agg[e]['minor']+eco_agg[e]['patch']+eco_agg[e]['other'] for e in sorted(eco_agg.keys())]) + ',backgroundColor:["#0d6efd","#6610f2","#6f42c1","#20c997","#fd7e14","#198754","#dc3545","#6c757d"]}]},options:{responsive:true,plugins:{legend:{labels:{color:cc.text}}}});} }catch(e){}}\n' 
            'function applyThemeToCharts(){cc=cssColors();if(chartTypes){chartTypes.options.scales.x.ticks.color=cc.text;chartTypes.options.scales.x.grid.color=cc.grid;chartTypes.options.scales.y.ticks.color=cc.text;chartTypes.options.scales.y.grid.color=cc.grid;chartTypes.update();} if(chartEcos){chartEcos.options.plugins.legend.labels.color=cc.text;chartEcos.update();}} \n' 
            ''
            ''
            ''
            ''
            ''
          '</script>')
          html.append('</body></html>')
          with open(html_path,'w',encoding='utf-8') as f:
              f.write(''.join(html))
          print(f"HTML generado en {html_path}")
          PY

      - name: üì§ Subir HTML del reporte
        if: ${{ inputs.generate_html_report }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-html
          path: docs/${{ inputs.html_report_name }}
      - name: üì§ Subir PDF del reporte
        if: ${{ inputs.generate_pdf_report && steps.generate_pdf.outputs.created == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-pdf
          path: docs/${{ inputs.pdf_report_name }}

      - name: üí¨ Comentar Issue con enlace al PDF
        if: ${{ (inputs.generate_pdf_report || inputs.generate_html_report) && steps.create_issue.outputs.issue_url != '' }}
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          REPO: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
        run: |
          python3 - << 'PY'
          import os, re, subprocess, json
          repo = os.getenv('REPO')
          run_id = os.getenv('RUN_ID')
          issue_url = os.getenv('ISSUE_URL','')
          m = re.search(r"/issues/(\d+)", issue_url)
          if not m:
              raise SystemExit(0)
          num = m.group(1)
          try:
              r = subprocess.run(['gh','api',f'repos/{repo}/actions/runs/{run_id}/artifacts'], capture_output=True, text=True)
              artifacts = json.loads(r.stdout) if r.returncode == 0 else {}
          except Exception:
              artifacts = {}
          server = os.getenv('GITHUB_SERVER_URL','https://github.com')
          run_link = f"{server}/{repo}/actions/runs/{run_id}"
          links = []
          try:
              for a in artifacts.get('artifacts', []):
                  if a.get('name') in ['dependabot-report-pdf','dependabot-report-html']:
                      if 'archive_download_url' in a:
                          links.append(f"{a['name']}: {a['archive_download_url']}")
          except Exception:
              pass
          body = ""
          if links:
              body += "Descargar reportes (zip):\n" + "\n".join(links) + "\n\n"
          body += f"Descargar reportes desde el run: {run_link}\n"
          subprocess.run(['gh','issue','comment',num,'--repo',repo,'--body',body], check=False)
          PY

      - name: üõë Cerrar PRs de Dependabot
        if: ${{ inputs.close_dependabot_prs && steps.detect_prs.outputs.prs_count != '0' && steps.create_issue.outputs.issue_url != '' && !inputs.dry_run_close }}
        env:
          GH_TOKEN: ${{ github.token }}
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          SKIP_CLOSE_LABELS: ${{ inputs.skip_close_labels }}
        run: |
          python3 - << 'PY'
          import json, os, subprocess
          from pathlib import Path
          prs = json.loads(os.getenv('PRS_DATA','[]'))
          closed = 0
          debug_path = Path('docs')/ 'output.txt'
          issue_url = os.getenv('ISSUE_URL','')
          skip_labels = [s.strip().lower() for s in os.getenv('SKIP_CLOSE_LABELS','').split(',') if s.strip()]
          for pr in prs:
              num = pr.get('number')
              if not num:
                  continue
              # Solo cerrar PRs que est√°n abiertos
              if (pr.get('state','') or '').lower() != 'open':
                  continue
              repo = os.getenv('GITHUB_REPOSITORY')
              labels = [ (l.get('name','') or '').lower() for l in pr.get('labels',[]) ]
              if skip_labels and any(l in skip_labels for l in labels):
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Skipped closing PR #{num} due to labels: {', '.join(labels)}\n")
                  except Exception:
                      pass
                  continue
              comment = 'Cerrado por reporte consolidado de Dependabot'
              if issue_url:
                  comment += f" ‚Äî Reporte: {issue_url}"
              r = subprocess.run(['gh','pr','close',str(num),'--repo',repo,'--delete-branch','--comment',comment], capture_output=True, text=True)
              if r.returncode == 0:
                  closed += 1
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Closed PR #{num}\n")
                  except Exception:
                      pass
              else:
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Failed to close PR #{num}: {r.stderr.strip()}\n")
                  except Exception:
                      pass
          print(f"üîí PRs cerrados: {closed}")
          PY

      - name: üìä Generate Summary
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PRS_COUNT: ${{ steps.detect_prs.outputs.prs_count }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          TRIGGER_DEPENDABOT_NOW: ${{ inputs.trigger_dependabot_now }}
          MAX_SUMMARY: ${{ inputs.max_prs_in_summary }}
          FAST_SUMMARY: ${{ inputs.fast_summary }}
        run: |
          cat > /tmp/generate_summary.py << 'SCRIPT_EOF'
          # Genera el summary del job con tablas, badges y agrupaci√≥n por directorio
          import json, os
          from datetime import datetime, timezone

          repo = os.getenv('GITHUB_REPOSITORY')
          server_url = os.getenv('GITHUB_SERVER_URL', 'https://github.com')

          try:
              prs_raw = os.getenv('PRS_DATA', '[]')
              prs_data = json.loads(prs_raw) if prs_raw and prs_raw.strip() != '' else []
          except Exception as e:
              print(f"::debug::Error parseando PRs: {e}")
              prs_data = []

          prs_count = int(os.getenv('PRS_COUNT', '0'))
          issue_url = os.getenv('ISSUE_URL','')

          def current_state(num: int):
              # Obtiene estado actual del PR (open/merged/closed) si no est√° en modo r√°pido
              try:
                  r = os.popen(f"gh api repos/{repo}/pulls/{num}").read()
                  data = json.loads(r)
                  st = data.get('state','open')
                  merged_at = data.get('merged_at')
                  if st == 'closed' and merged_at:
                      return 'merged'
                  return st
              except Exception:
                  return 'unknown'

          def status_badge(state: str):
              # Genera badge visual para el estado del PR
              color = {'open':'brightgreen','closed':'lightgrey','merged':'purple','unknown':'blue'}.get(state,'blue')
              return f"<img src='https://img.shields.io/badge/status-{state}-{color}?style=flat-square' alt='{state}'/>"

          def label_badges(labels):
              # Genera badges para cada label incluyendo color
              parts = []
              for l in labels:
                  name = l.get('name','')
                  color = l.get('color','0366d6')
                  if not name:
                      continue
                  parts.append(f"<img src='https://img.shields.io/badge/{name.replace('-', '--')}-{color}?style=flat-square' alt='{name}' style='margin:2px'>")
              return ' '.join(parts) if parts else '‚ûñ'

          def days_ago(iso):
              # Calcula edad en d√≠as desde fecha ISO
              try:
                  dt = datetime.fromisoformat(iso.replace('Z', '+00:00'))
                  now = datetime.now(timezone.utc)
                  return (now - dt).days
              except Exception:
                  return None

          def parse_title(t):
              # Extrae paquete/versions/directorio desde t√≠tulo de Dependabot
              import re
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None

          def semver_tuple(s):
              import re
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)

          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n a partir de versiones
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'

          def directory_of(pr):
              meta = parse_title(pr.get('title','')) or {'dir':''}
              d = meta.get('dir','')
              if d:
                  return d
              ref = pr.get('headRefName','')
              if '/' in ref:
                  try:
                      parts = ref.split('/')
                      idx = parts.index('dependabot') if 'dependabot' in parts else -1
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'

          def sort_key(pr):
              order = {'open':0,'merged':1,'closed':2,'unknown':3}
              st = pr.get('state','open')
              try:
                  ts = datetime.fromisoformat(pr.get('createdAt','').replace('Z','+00:00')).timestamp()
              except Exception:
                  ts = 0
              return (order.get(st,3), -ts)

          summary = []
          summary.append("# üîÑ Pull Requests de Dependabot\n\n")
          if issue_url:
              summary.append(f"> üßæ <b>Reporte consolidado:</b> <a href='{issue_url}'>{issue_url}</a>\n\n")
          if os.getenv('TRIGGER_DEPENDABOT_NOW','false') == 'true':
              cfg_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
              summary.append(f"> ‚ö° <b>Trigger enviado</b>: se edit√≥ <a href='{cfg_url}'>dependabot.yml</a> para forzar un job de actualizaci√≥n.\n\n")

          if prs_data and len(prs_data) > 0:
              try:
                  max_summary = int(os.getenv('MAX_SUMMARY','30'))
              except Exception:
                  max_summary = 30
              prs_sorted = sorted(prs_data, key=sort_key)
              show_list = prs_sorted[:min(prs_count, max_summary)]

              agg = {'major':0,'minor':0,'patch':0,'other':0}
              for pr in show_list:
                  meta = parse_title(pr.get('title',''))
                  if meta and meta['from'] and meta['to']:
                      agg[update_type(meta['from'], meta['to'])] += 1

              summary.append(f"Mostrando {len(show_list)} de {prs_count} PRs\n\n")
              fast = os.getenv('FAST_SUMMARY','true').lower() == 'true'

              def state_of(pr):
                  num = pr.get('number')
                  return pr.get('state','open') if fast else current_state(num)

              def render_table(items, title, opened):
                  summary.append("<details open>\n" if opened else "<details>\n")
                  summary.append(f"<summary><h2>üîÑ {title} ({len(items)})</h2></summary>\n\n")
                  summary.append("<table>\n")
                  summary.append("<thead>\n")
                  summary.append("<tr>\n")
                  summary.append("<th>PR</th><th>Paquete</th><th>Desde</th><th>Hasta</th><th>Dir</th><th>Estado</th><th>Labels</th><th>Edad</th>\n")
                  summary.append("</tr>\n")
                  summary.append("</thead>\n")
                  summary.append("<tbody>\n")
                  for pr in items:
                      pr_number = pr.get('number','N/A')
                      pr_url = pr.get('url','#')
                      pr_title = pr.get('title','Sin t√≠tulo')
                      lbl_html = label_badges(pr.get('labels',[]))
                      created = pr.get('createdAt','')
                      d_ago = days_ago(created)
                      state_now = state_of(pr)
                      meta = parse_title(pr_title) or {'name':'‚Äî','from':'‚Äî','to':'‚Äî','dir':directory_of(pr)}
                      summary.append("<tr>\n")
                      summary.append(f"<td><a href='{pr_url}'><b>#{pr_number}</b></a></td>\n")
                      summary.append(f"<td>{meta['name']}</td>\n")
                      summary.append(f"<td>{meta['from']}</td>\n")
                      summary.append(f"<td>{meta['to']}</td>\n")
                      summary.append(f"<td><code>{meta['dir'] or '/'}</code></td>\n")
                      summary.append(f"<td>{status_badge(state_now)}</td>\n")
                      summary.append(f"<td>{lbl_html}</td>\n")
                      summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                      summary.append("</tr>\n")
                  summary.append("</tbody>\n")
                  summary.append("</table>\n\n")
                  summary.append("</details>\n\n")

              open_items, merged_items, closed_items = [], [], []
              for pr in show_list:
                  st = state_of(pr)
                  if st == 'open':
                      open_items.append(pr)
                  elif st == 'merged':
                      merged_items.append(pr)
                  elif st == 'closed':
                      closed_items.append(pr)

              render_table(open_items, 'Abiertos', True)
              render_table(merged_items, 'Fusionados', False)
              render_table(closed_items, 'Cerrados', False)

              if prs_count > len(show_list):
                  prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+is%3Aopen+author%3Aapp%2Fdependabot"
                  summary.append(f"> <a href='{prs_url}'>üìã <b>Ver todos los PRs ({prs_count})</b></a>\n\n")

              summary.append("<details>\n")
              summary.append("<summary><h2>üìÅ Detalles por directorio</h2></summary>\n\n")
              groups = {}
              for pr in show_list:
                  d = directory_of(pr)
                  groups.setdefault(d or '/', []).append(pr)
              for d in sorted(groups.keys()):
                  items = groups[d]
                  summary.append(f"<h3><code>{d or '/'}</code> ({len(items)})</h3>\n")
                  summary.append("<table>\n<thead>\n<tr>\n<th>PR</th><th>Paquete</th><th>Tipo</th><th>Edad</th>\n</tr>\n</thead>\n<tbody>\n")
                  for pr in items:
                      pr_number = pr.get('number','N/A')
                      pr_url = pr.get('url','#')
                      pr_title = pr.get('title','Sin t√≠tulo')
                      created = pr.get('createdAt','')
                      d_ago = days_ago(created)
                      meta = parse_title(pr_title) or {'name':'‚Äî','from':'','to':''}
                      typ = '‚Äî'
                      if meta['from'] and meta['to']:
                          typ = update_type(meta['from'], meta['to'])
                      typ_badge = f"<img src='https://img.shields.io/badge/update-{typ}-informational?style=flat-square' alt='{typ}'/>"
                      summary.append("<tr>\n")
                      summary.append(f"<td><a href='{pr_url}'>#{pr_number}</a></td>\n")
                      summary.append(f"<td>{meta['name']}</td>\n")
                      summary.append(f"<td>{typ_badge}</td>\n")
                      summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                      summary.append("</tr>\n")
                  summary.append("</tbody>\n</table>\n\n")
              summary.append("</details>\n\n")
          else:
              summary.append("> ‚ÑπÔ∏è No hay PRs activos de Dependabot en este momento.\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>‚öôÔ∏è C√≥mo activar manualmente</h2></summary>\n\n")
          dep_graph = f"{server_url}/{repo}/network/dependencies"
          prs_link = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          summary.append("1) Ve a <b>Insights ‚Üí Dependency graph ‚Üí Dependabot</b>\n")
          summary.append(f"2) En <b>Recent update jobs</b>, pulsa <b>Check for updates</b> ‚Ä¢ <a href='{dep_graph}'>Acceder</a>\n")
          summary.append(f"3) Revisa nuevos PRs: <a href='{prs_link}'>Listado de PRs de Dependabot</a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>üìÑ Reportes Exportados</h2></summary>\n\n")
          run_id = os.getenv('GITHUB_RUN_ID','')
          if run_id:
              run_link = f"{server_url}/{repo}/actions/runs/{run_id}"
              summary.append(f"- PDF/HTML: <a href='{run_link}'>Descargar desde el run</a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>üîó Enlaces √ötiles</h2></summary>\n\n")
          config_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
          security_url = f"{server_url}/{repo}/settings/security_analysis"
          insights_url = f"{server_url}/{repo}/network/dependencies"
          labels_url = f"{server_url}/{repo}/labels"
          prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          advisories_url = f"{server_url}/{repo}/security/dependabot"
          summary.append(f"- üìù <a href='{config_url}'><b>Ver Configuraci√≥n</b></a>\n")
          summary.append(f"- üõ°Ô∏è <a href='{security_url}'><b>Security Settings</b></a>\n")
          summary.append(f"- üìä <a href='{insights_url}'><b>Dependency Graph</b></a>\n")
          summary.append(f"- üè∑Ô∏è <a href='{labels_url}'><b>Gestionar Labels</b></a>\n")
          summary.append(f"- üîÑ <a href='{prs_url}'><b>PRs de Dependabot</b></a>\n")
          summary.append(f"- üö® <a href='{advisories_url}'><b>Security Alerts</b></a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>‚ÑπÔ∏è Informaci√≥n</h2></summary>\n\n")
          summary.append("- üîç Detecci√≥n y resumen inteligente de PRs\n")
          summary.append("- üè∑Ô∏è Badges de estado y labels\n")
          summary.append("- ‚è±Ô∏è Edad de PRs y ordenamiento\n")
          summary.append("- üìÅ Secci√≥n por directorio\n")
          summary.append("- üîó Enlaces √∫tiles de UI\n\n")
          summary.append("</details>\n\n")

          timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          workflow_url = f"{server_url}/jersonmartinez/reusable-workflows"
          summary.append(f"<sub>ü§ñ Generado por <a href='{workflow_url}'><b>Reusable Workflows</b></a> ‚Ä¢ {timestamp}</sub>\n")

          with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
              f.write(''.join(summary))

          print("‚úÖ Summary generado correctamente")
          print(f"üìä PRs detectados: {prs_count}")
          SCRIPT_EOF

          python3 /tmp/generate_summary.py

      - name: üíæ Subir artifact de depuraci√≥n
        if: ${{ inputs.upload_debug_artifact }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-debug
          path: docs/output.txt
