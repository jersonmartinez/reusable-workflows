name: Setup Dependabot

on:
  workflow_call:
    inputs:

      create_issue:
        required: false
        type: boolean
        default: true

      issue_title:
        required: false
        type: string
        default: 'Reporte Dependabot: ${date}'

      issue_labels:
        required: false
        type: string
        default: 'dependabot-report'

      close_dependabot_prs:
        required: false
        type: boolean
        default: true

      wait_minutes:
        required: false
        type: number
        default: 5

      create_missing_labels:
        required: false
        type: boolean
        default: false

      create_issue_if_empty:
        required: false
        type: boolean
        default: true

      upload_debug_artifact:
        required: false
        type: boolean
        default: true

      trigger_dependabot_now:
        required: false
        type: boolean
        default: false

      dependabot_config_path:
        required: false
        type: string
        default: '.github/dependabot.yml'

      dependabot_logins:
        required: false
        type: string
        default: 'dependabot,dependabot[bot],app/dependabot'

      poll_interval_seconds:
        required: false
        type: number
        default: 30

      dry_run_close:
        required: false
        type: boolean
        default: false

      skip_close_labels:
        required: false
        type: string
        default: ''

      max_prs_in_summary:
        required: false
        type: number
        default: 30

      generate_pdf_report:
        required: false
        type: boolean
        default: false

      pdf_report_name:
        required: false
        type: string
        default: 'dependabot-report.pdf'

      generate_html_report:
        required: false
        type: boolean
        default: true

      html_report_name:
        required: false
        type: string
        default: 'dependabot-report.html'
      fast_summary:
        required: false
        type: boolean
        default: true

      prs_state:
        required: false
        type: string
        default: 'all'

      company_name:
        required: false
        type: string
        default: 'PRB'


      logo_url:
        required: false
        type: string
        default: 'https://extranet.prb.com.mx/Prb1.2/images/logos/logo_PRB.svg'

jobs:
  configure:
    name: Configuring
    runs-on: ubuntu-latest
    timeout-minutes: 45
    concurrency:
      group: dependabot-report
      cancel-in-progress: true
    outputs:
      prs_data: ${{ steps.detect_prs.outputs.prs_data }}
      issue_url: ${{ steps.create_issue.outputs.issue_url }}
      alerts_data: ${{ steps.collect_alerts.outputs.alerts_data }}

    steps:
      - name: ğŸš€ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ†” Determine Workflow Ref
        id: workflow_ref
        run: |
          WORKFLOW_REF="${{ github.workflow_ref }}"
          if [ -z "$WORKFLOW_REF" ]; then
            echo "ref=${{ github.ref }}" >> $GITHUB_OUTPUT
            echo "repo=${{ github.repository }}" >> $GITHUB_OUTPUT
          else
            REF=$(echo "$WORKFLOW_REF" | cut -d'@' -f2)
            REPO=$(echo "$WORKFLOW_REF" | cut -d'/' -f1,2)
            echo "ref=$REF" >> $GITHUB_OUTPUT
            echo "repo=$REPO" >> $GITHUB_OUTPUT
          fi

      - name: ğŸ“¥ Checkout Scripts
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.workflow_ref.outputs.repo }}
          ref: ${{ steps.workflow_ref.outputs.ref }}
          path: .reusable-scripts

      - name: ğŸ•µï¸ Debug Scripts Existence
        run: |
          echo "Listing .reusable-scripts content:"
          ls -R .reusable-scripts || echo ".reusable-scripts not found"
          echo "Listing root scripts (if any):"
          ls -R scripts || echo "scripts not found in root"

      - name: ğŸ•’ Marcar inicio
        if: false
        run: echo "skip"

      - name: ğŸ§ª Preparar logs de depuraciÃ³n
        run: |
          mkdir -p docs
          printf "[START] Dependabot report debug at %s\n" "$(date -u +'%Y-%m-%d %H:%M:%SZ')" > docs/output.txt

      - name: âš¡ Trigger Dependabot (opcional)
        if: ${{ inputs.trigger_dependabot_now }}
        env:
          GH_TOKEN: ${{ github.token }}
          CFG_PATH: ${{ inputs.dependabot_config_path }}
        run: |
          set -e
          if [ ! -f "$CFG_PATH" ]; then
            echo "::warning::No existe $CFG_PATH. No se puede forzar ejecuciÃ³n"
            exit 0
          fi
          TS=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          echo "# trigger: $TS" >> "$CFG_PATH"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$CFG_PATH"
          if git diff --cached --quiet; then
            echo "Sin cambios en $CFG_PATH"
          else
            git commit -m "chore(dependabot): trigger run at $TS"
            git push || echo "::warning::No se pudo pushear cambios (verificar permisos)"
            echo "Triggered Dependabot via config change at $TS" >> docs/output.txt
          fi

      - name: ğŸ” Validate Labels
        id: validate_labels
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          cat > /tmp/validate_labels.py << 'SCRIPT_EOF'
          import json, os, subprocess, sys
          from collections import defaultdict

          repo = os.getenv('GITHUB_REPOSITORY')

          try:
              result = subprocess.run(
                  ['gh', 'label', 'list', '--repo', repo, '--json', 'name,color,description', '--limit', '1000'],
                  capture_output=True, text=True, check=True
              )
              labels_data = json.loads(result.stdout)
              existing_labels = {label['name'].lower(): label for label in labels_data}
          except Exception as e:
              print(f"::error::No se pudieron obtener los labels: {e}")
              existing_labels = {}

          try:
              ecosystems = json.loads('''${{ inputs.ecosystems }}''')
          except json.JSONDecodeError as e:
              print(f"::error::Error al parsear ecosistemas: {e}")
              sys.exit(1)

          missing_by_ecosystem = defaultdict(list)
          valid_by_ecosystem = defaultdict(list)
          filtered_ecosystems = []
          all_missing = set()

          for eco in ecosystems:
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              valid_labels = []
              
              for label in labels:
                  if label.lower() in existing_labels:
                      valid_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      valid_labels.append(label)
                  else:
                      missing_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      all_missing.add(label)

              # Crear ecosistema filtrado con SOLO labels vÃ¡lidos
              filtered_eco = eco.copy()
              filtered_eco['labels'] = ','.join(valid_labels)
              filtered_ecosystems.append(filtered_eco)

          # Generar outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"missing_labels={','.join(sorted(all_missing))}\n")
              f.write(f"missing_count={len(all_missing)}\n")
              f.write(f"valid_count={sum(len(v) for v in valid_by_ecosystem.values())}\n")
              f.write(f"has_missing={'true' if all_missing else 'false'}\n")
              
              # Exportar ecosistemas filtrados
              filtered_json = json.dumps(filtered_ecosystems)
              f.write(f"filtered_ecosystems<<EOF\n")
              f.write(f"{filtered_json}\n")
              f.write(f"EOF\n")

          # Guardar datos para el summary
          with open('/tmp/validation_data.json', 'w') as f:
              json.dump({
                  'missing_by_ecosystem': dict(missing_by_ecosystem),
                  'valid_by_ecosystem': dict(valid_by_ecosystem),
                  'existing_labels': existing_labels
              }, f)

          if all_missing:
              print(f"::warning title=Labels Faltantes::Se encontraron {len(all_missing)} labels sin configurar. SerÃ¡n omitidos del archivo generado.")
              for label in sorted(all_missing):
                  print(f"  âš ï¸ {label}")
          else:
              print("::notice title=ValidaciÃ³n Exitosa::Todos los labels estÃ¡n configurados correctamente")
          
          print(f"\nğŸ“Š Resumen:")
          print(f"  âœ… Labels vÃ¡lidos: {sum(len(v) for v in valid_by_ecosystem.values())}")
          print(f"  âš ï¸ Labels faltantes: {len(all_missing)}")
          print(f"  ğŸ“¦ Ecosistemas: {len(ecosystems)}")
          SCRIPT_EOF

          python3 /tmp/validate_labels.py

      - name: ğŸ·ï¸ Crear labels faltantes
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          MISSING="${{ steps.validate_labels.outputs.missing_labels }}"
          REPO="$GITHUB_REPOSITORY"
          IFS=',' read -ra LABELS <<< "$MISSING"
          for l in "${LABELS[@]}"; do
            [ -z "$l" ] && continue
            gh label create "$l" --repo "$REPO" --color 0366d6 --description "Auto-creado para Dependabot" || true
            echo "Creado label: $l"
          done

      - name: ğŸ·ï¸ Crear labels del Issue faltantes
        if: ${{ inputs.issue_labels != '' && inputs.create_missing_labels }}
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
        run: |
          REPO="$GITHUB_REPOSITORY"
          EXISTING=$(gh label list --repo "$REPO" --json name --jq '.[].name')
          declare -A MAP
          for n in $EXISTING; do MAP[$n]=1; done
          IFS=',' read -ra LBS <<< "$ISSUE_LABELS"
          for l in "${LBS[@]}"; do
            NAME=$(echo "$l" | xargs)
            [ -z "$NAME" ] && continue
            if [ -z "${MAP[$NAME]}" ]; then
              gh label create "$NAME" --repo "$REPO" --color 6f42c1 --description "Auto-creado para reporte" || true
              echo "Creado label de Issue: $NAME"
            fi
          done

      - name: ğŸ“ Generate Dependabot Config
        if: false
        env:
          FILTERED_ECOSYSTEMS: ${{ steps.validate_labels.outputs.filtered_ecosystems }}
        run: |
          cat > /tmp/generate_config.py << 'SCRIPT_EOF'
          import json, os, sys

          try:
              ecosystems = json.loads(os.getenv('FILTERED_ECOSYSTEMS', '[]'))
          except json.JSONDecodeError as e:
              print(f"::error::JSON invÃ¡lido: {e}")
              sys.exit(1)

          if not ecosystems:
              print("::error::No hay ecosistemas para configurar")
              sys.exit(1)

          schedule = '${{ inputs.schedule }}'
          pr_limit = ${{ inputs.pr_limit }}
          target_branch = '${{ inputs.target_branch }}'

          config = {'version': 2, 'updates': []}

          for eco in ecosystems:
              update = {
                  'package-ecosystem': eco['ecosystem'],
                  'directory': eco['directory'],
                  'schedule': {'interval': schedule},
                  'open-pull-requests-limit': eco.get('pr_limit', pr_limit)
              }

              if target_branch:
                  update['target-branch'] = target_branch

              # Los labels ya estÃ¡n filtrados (solo vÃ¡lidos)
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              if labels:
                  update['labels'] = labels

              prefix = eco.get('prefix', '').strip()
              if prefix:
                  update['commit-message'] = {'prefix': prefix}

              config['updates'].append(update)

          import yaml
          os.makedirs('.github', exist_ok=True)

          with open('.github/dependabot.yml', 'w') as f:
            yaml.dump(config, f, sort_keys=False, default_flow_style=False, indent=2)

          print("âœ… ConfiguraciÃ³n generada exitosamente (solo con labels vÃ¡lidos)")

          with open('.github/dependabot.yml', 'r') as f:
              content = f.read()
              print("\nğŸ“„ Contenido generado:")
              print(content)
          SCRIPT_EOF

          python3 /tmp/generate_config.py

      - name: ğŸ’¾ Commit Changes
        id: commit
        if: false
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          if git diff --quiet .github/dependabot.yml; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "ğŸ“Œ Sin cambios - La configuraciÃ³n estÃ¡ actualizada"
          else
            git add .github/dependabot.yml
            git commit -m "chore: update dependabot configuration"
            git push
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "commit_sha=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
            echo "âœ… Cambios commiteados y pusheados"
          fi

      - name: ğŸ”„ Detect Dependabot PRs
        id: detect_prs
        env:
          GH_TOKEN: ${{ github.token }}
          WAIT_MINUTES: ${{ inputs.wait_minutes }}
          POLL_INTERVAL: ${{ inputs.poll_interval_seconds }}
          DEP_LOGINS: ${{ inputs.dependabot_logins }}
          PRS_STATE: ${{ inputs.prs_state }}
          TRIGGER_DEPENDABOT_NOW: ${{ inputs.trigger_dependabot_now }}
        run: |
          SCRIPT_PATH=".reusable-scripts/scripts/detect_prs.py"
          if [ ! -f "$SCRIPT_PATH" ] && [ -f "scripts/detect_prs.py" ]; then
            SCRIPT_PATH="scripts/detect_prs.py"
          fi
          # Fallback: Create script if missing (e.g. not pushed yet)
          if [ ! -f "$SCRIPT_PATH" ]; then
            echo "::warning::Script not found at $SCRIPT_PATH. Using inline fallback."
            mkdir -p .reusable-scripts/scripts
            cat > "$SCRIPT_PATH" << 'PY_EOF'
          import json, os, subprocess, time
          def main():
              wait_minutes = int(os.getenv('WAIT_MINUTES', '10'))
              poll_interval = int(os.getenv('POLL_INTERVAL', '30'))
              repo = os.getenv('GITHUB_REPOSITORY')
              debug_path = os.path.join('docs','output.txt')
              dep_logins = [s.strip() for s in os.getenv('DEP_LOGINS','dependabot,dependabot[bot],app/dependabot').split(',') if s.strip()]
              def log(msg):
                  try:
                      os.makedirs(os.path.dirname(debug_path), exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(msg + "\n")
                  except Exception:
                      pass
              def list_prs_api():
                  try:
                      state = os.getenv('PRS_STATE','open')
                      path = f"repos/{repo}/pulls?state={state}&per_page=100"
                      args = ['gh','api',path,'--method','GET']
                      result = subprocess.run(args, capture_output=True, text=True)
                      if result.returncode == 0 and result.stdout.strip():
                          data = json.loads(result.stdout)
                          filtered = []
                          for pr in data:
                              login = (pr.get('user',{}) or {}).get('login','')
                              if login in dep_logins:
                                  filtered.append({
                                      'number': pr.get('number'),
                                      'title': pr.get('title'),
                                      'url': pr.get('html_url'),
                                      'labels': pr.get('labels',[]),
                                      'createdAt': pr.get('created_at',''),
                                      'headRefName': (pr.get('head',{}) or {}).get('ref',''),
                                      'state': pr.get('state','')
                                  })
                          return filtered
                      log(f"list_prs_api non-0 returncode: {result.returncode} stderr={result.stderr.strip()}")
                      return []
                  except Exception as e:
                      log(f"list_prs_api exception: {e}")
                      return []
              def list_prs_search():
                  try:
                      state = os.getenv('PRS_STATE','open')
                      qp = [f"repo:{repo}", "is:pr", "(author:app/dependabot OR author:dependabot OR author:dependabot[bot])"]
                      if state == 'all':
                          qp.append("(is:open OR is:closed)")
                      elif state in ('open','closed'):
                          qp.append(f"is:{state}")
                      q = " ".join(qp)
                  except Exception:
                      q = ""
                  if not q:
                      return []
                  try:
                      result = subprocess.run(['gh','api','search/issues','-f',f"q={q}",'-f','per_page=100'], capture_output=True, text=True)
                      if result.returncode == 0 and result.stdout.strip():
                          data = json.loads(result.stdout)
                          items = data.get('items',[])
                          out = []
                          for it in items:
                              out.append({
                                  'number': it.get('number'),
                                  'title': it.get('title'),
                                  'url': it.get('html_url'),
                                  'labels': it.get('labels',[]),
                                  'createdAt': it.get('created_at',''),
                                  'headRefName': '',
                                  'state': it.get('state','')
                              })
                          return out
                      log(f"list_prs_search non-0 returncode: {result.returncode} stderr={result.stderr.strip()}")
                  except Exception as e:
                      log(f"list_prs_search exception: {e}")
                  return []
              def list_prs_search_label_only():
                  try:
                      state = os.getenv('PRS_STATE','open')
                      qp = [f"repo:{repo}", "is:pr", "label:dependencies"]
                      if state == 'all':
                          qp.append("(is:open OR is:closed)")
                      elif state in ('open','closed'):
                          qp.append(f"is:{state}")
                      q = " ".join(qp)
                  except Exception:
                      q = ""
                  if not q:
                      return []
                  try:
                      result = subprocess.run(['gh','api','search/issues','-f',f"q={q}",'-f','per_page=100'], capture_output=True, text=True)
                      if result.returncode == 0 and result.stdout.strip():
                          data = json.loads(result.stdout)
                          items = data.get('items',[])
                          out = []
                          for it in items:
                              out.append({
                                  'number': it.get('number'),
                                  'title': it.get('title'),
                                  'url': it.get('html_url'),
                                  'labels': it.get('labels',[]),
                                  'createdAt': it.get('created_at',''),
                                  'headRefName': '',
                                  'state': it.get('state','')
                              })
                          return out
                      log(f"list_prs_search_label_only non-0 returncode: {result.returncode} stderr={result.stderr.strip()}")
                  except Exception as e:
                      log(f"list_prs_search_label_only exception: {e}")
                  return []
              prs = list_prs_api()
              log(f"Initial PRs count: {len(prs)}")
              if len(prs) == 0:
                  fb = list_prs_search()
                  if fb:
                      prs = fb
                  else:
                      fb2 = list_prs_search_label_only()
                      if fb2:
                          prs = fb2
                  log(f"Immediate fallback PRs count: {len(prs)}")
              should_wait = (os.getenv('TRIGGER_DEPENDABOT_NOW','false') == 'true' and os.getenv('PRS_STATE','open') == 'open' and wait_minutes > 0)
              deadline = time.time() + (wait_minutes*60 if should_wait else 0)
              while should_wait and len(prs) == 0 and time.time() < deadline:
                  time.sleep(poll_interval)
                  prs = list_prs_api()
                  log(f"Polling... PRs count: {len(prs)}")
              if len(prs) == 0:
                  fallback = list_prs_search()
                  if fallback:
                      prs = fallback
                  else:
                      fallback2 = list_prs_search_label_only()
                      if fallback2:
                          prs = fallback2
                  log(f"Fallback PRs count: {len(prs)}")
              with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                  f.write('prs_data<<EOF\n')
                  f.write(json.dumps(prs))
                  f.write('\nEOF\n')
                  f.write(f"prs_count={len(prs)}\n")
              print(f"ğŸ“Š PRs detectados: {len(prs)}")
          if __name__ == '__main__':
              main()
          PY_EOF
          fi
          python3 "$SCRIPT_PATH"

      - name: ğŸ“¦ Recoger alertas de Dependabot
        id: collect_alerts
        env:
          GH_TOKEN: ${{ github.token }}
          REPO: ${{ github.repository }}
        run: |
          python3 - << 'PY'
          import os, json, subprocess
          repo = os.getenv('REPO','')
          alerts = []
          try:
              r = subprocess.run(['gh','api', f'repos/{repo}/dependabot/alerts', '-f', 'state=open', '-f', 'per_page=100'], capture_output=True, text=True)
              if r.returncode == 0 and r.stdout.strip():
                  data = json.loads(r.stdout)
                  if isinstance(data, list):
                      alerts = data
          except Exception:
              alerts = []
          with open(os.environ['GITHUB_OUTPUT'],'a') as f:
              f.write('alerts_data<<EOF\n')
              f.write(json.dumps(alerts))
              f.write('\nEOF\n')
          PY

      - name: ğŸ’¾ Guardar PRs detectados
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
        run: |
          mkdir -p docs
          echo "$PRS_DATA" > docs/prs.json

      - name: ğŸ§¾ Crear Issue de Reporte
        id: create_issue
        if: ${{ inputs.create_issue && (steps.detect_prs.outputs.prs_count != '0' || inputs.create_issue_if_empty) }}
        env:
          GH_TOKEN: ${{ github.token }}
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          ISSUE_TITLE_TPL: ${{ inputs.issue_title }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          SCRIPT_PATH=".reusable-scripts/scripts/create_issue.py"
          if [ ! -f "$SCRIPT_PATH" ] && [ -f "scripts/create_issue.py" ]; then
            SCRIPT_PATH="scripts/create_issue.py"
          fi
          if [ ! -f "$SCRIPT_PATH" ]; then
            echo "::warning::Script not found at $SCRIPT_PATH. Using inline fallback."
            mkdir -p .reusable-scripts/scripts
            cat > "$SCRIPT_PATH" << 'PY_EOF'
          import json, os, re, subprocess
          from datetime import datetime, timezone
          debug_path = os.path.join('docs','output.txt')
          def log(msg):
              try:
                  with open(debug_path,'a') as df:
                      df.write(msg + "\n")
              except Exception:
                  pass
          def pr_details(num, repo):
              try:
                  r = subprocess.run(['gh','pr','view',str(num),'--repo',repo,'--json','body'], capture_output=True, text=True)
                  if r.returncode == 0:
                      data = json.loads(r.stdout)
                      return data.get('body','')
                  return ''
              except Exception:
                  return ''
          def parse_title(t):
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None
          def semver_tuple(s):
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def build_body(prs, date, repo):
              lines = []
              run_id = os.getenv('RUN_ID','')
              server_url = os.getenv('SERVER_URL','https://github.com')
              if run_id:
                  lines.append(f"**Descargar reportes (PDF/HTML):** {server_url}/{repo}/actions/runs/{run_id}\n\n")
              lines.append(f"### Reporte de actualizaciones ({date})\n")
              if prs:
                  agg = {'major':0,'minor':0,'patch':0,'other':0}
                  lines.append("\n| PR | Paquete | Desde | Hasta | Dir | Labels |\n")
                  lines.append("|:--:|:-------|:-----:|:-----:|:---:|:------:|\n")
                  for pr in prs:
                      num = pr.get('number')
                      url = pr.get('url')
                      title_pr = pr.get('title','')
                      meta = parse_title(title_pr) or {'name':'â€”','from':'â€”','to':'â€”','dir':''}
                      labels_pr = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or 'â€”'
                      lines.append(f"| [#{num}]({url}) | {meta['name']} | {meta['from']} | {meta['to']} | {meta['dir']} | {labels_pr} |\n")
                      if meta['from'] != 'â€”' and meta['to'] != 'â€”':
                          agg[update_type(meta['from'], meta['to'])] += 1
                  lines.append("\n#### Resumen por tipo\n")
                  lines.append(f"- Major: {agg['major']}\n- Minor: {agg['minor']}\n- Patch: {agg['patch']}\n- Other: {agg['other']}\n")
                  lines.append("\n#### Detalles\n")
                  for pr in prs:
                      num = pr.get('number')
                      url = pr.get('url')
                      title_pr = pr.get('title','')
                      body = pr_details(num, repo)
                      snippet = (body or '').strip()
                      if len(snippet) > 1200:
                          snippet = snippet[:1200] + 'â€¦'
                      lines.append(f"- [#{num}]({url}) {title_pr}\n")
                      if snippet:
                          lines.append(f"  \n  {snippet}\n")
              else:
                  lines.append("\nNo se encontraron PRs de Dependabot en este momento.\n")
              return ''.join(lines)
          def find_existing_issue(title, repo):
              try:
                  r = subprocess.run(['gh','issue','list','--repo',repo,'--state','open','--limit','100','--json','number,title,url'], capture_output=True, text=True)
                  if r.returncode == 0 and r.stdout.strip():
                      items = json.loads(r.stdout)
                      for it in items:
                          if it.get('title','') == title:
                              return it.get('url','')
                  return ''
              except Exception:
                  return ''
          def main():
              prs_raw = os.getenv('PRS_DATA','[]')
              prs = json.loads(prs_raw) if prs_raw.strip() else []
              date = datetime.now(timezone.utc).strftime('%Y-%m-%d')
              title_tpl = os.getenv('ISSUE_TITLE_TPL','Reporte Dependabot: ${date}')
              title = title_tpl.replace('${date}', date)
              labels = [l.strip() for l in os.getenv('ISSUE_LABELS','').split(',') if l.strip()]
              repo = os.getenv('GITHUB_REPOSITORY')
              existing = find_existing_issue(title, repo)
              if existing:
                  with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                      f.write(f"issue_url={existing}\n")
                  log(f"Issue existente reutilizado: {existing}")
                  print(f"ğŸ§¾ Issue reutilizado: {existing}")
                  return
              body = build_body(prs, date, repo)
              cmd = ['gh','issue','create','--repo',repo,'--title',title,'--body',body]
              for l in labels:
                  cmd += ['--label', l]
              result = subprocess.run(cmd, capture_output=True, text=True)
              url = ''
              if result.returncode == 0:
                  for line in result.stdout.splitlines():
                      if line.strip().startswith('https://'):
                          url = line.strip()
                          break
              else:
                  log(f"Fallo al crear issue con labels. stderr: {result.stderr.strip()}")
                  result2 = subprocess.run(['gh','issue','create','--repo',repo,'--title',title,'--body',body], capture_output=True, text=True)
                  if result2.returncode == 0:
                      for line in result2.stdout.splitlines():
                          if line.strip().startswith('https://'):
                              url = line.strip()
                              break
                  else:
                      log(f"Intento sin labels tambiÃ©n fallÃ³. stderr: {result2.stderr.strip()}")
              with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                  f.write(f"issue_url={url}\n")
              log(f"Issue title: {title}")
              log(f"Issue created: {url if url else 'N/A'}")
              print(f"ğŸ§¾ Issue creado: {url if url else 'N/A'}")
          if __name__ == '__main__':
              main()
          PY_EOF
          fi
          python3 "$SCRIPT_PATH"

      - name: ğŸ“„ Generar PDF del reporte
        id: generate_pdf
        if: false
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PDF_PATH: docs/${{ inputs.pdf_report_name }}
          REPO: ${{ github.repository }}
          GH_TOKEN: ${{ github.token }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
        run: |
          sudo apt-get update -y || true
          sudo apt-get install -y libcairo2 libcairo2-dev libpango1.0-dev libgdk-pixbuf2.0-dev pkg-config || true
          python3 -m pip install --user reportlab || true
          python3 -m pip install --user svglib lxml cssselect2 tinycss2 || true
          export PYTHONPATH="$(python3 -c 'import site; print(site.getusersitepackages())')${PYTHONPATH:+:$PYTHONPATH}"
          
          SCRIPT_PATH=".reusable-scripts/scripts/generate_pdf.py"
          if [ ! -f "$SCRIPT_PATH" ]; then
            if [ -f "scripts/generate_pdf.py" ]; then
              SCRIPT_PATH="scripts/generate_pdf.py"
            else
              echo "::error::Script not found at $SCRIPT_PATH"
              exit 1
            fi
          fi
          python3 "$SCRIPT_PATH"

      - name: ğŸ“Š Generate Summary
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PRS_COUNT: ${{ steps.detect_prs.outputs.prs_count }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          TRIGGER_DEPENDABOT_NOW: ${{ inputs.trigger_dependabot_now }}
          MAX_SUMMARY: ${{ inputs.max_prs_in_summary }}
          FAST_SUMMARY: ${{ inputs.fast_summary }}
          COMPANY_NAME: ${{ inputs.company_name }}
          GH_TOKEN: ${{ github.token }}
        run: |
          SCRIPT_PATH=".reusable-scripts/scripts/generate_summary.py"
          if [ ! -f "$SCRIPT_PATH" ] && [ -f "scripts/generate_summary.py" ]; then
            SCRIPT_PATH="scripts/generate_summary.py"
          fi
          if [ ! -f "$SCRIPT_PATH" ]; then
            echo "::warning::Script not found at $SCRIPT_PATH. Using inline fallback."
            mkdir -p .reusable-scripts/scripts
            cat > "$SCRIPT_PATH" << 'PY_EOF'
          import json, os
          from datetime import datetime, timezone
          from urllib.parse import quote_plus
          repo = os.getenv('GITHUB_REPOSITORY')
          server_url = os.getenv('GITHUB_SERVER_URL', 'https://github.com')
          company_name = (os.getenv('COMPANY_NAME','PRB') or 'PRB').strip()
          try:
              prs_raw = os.getenv('PRS_DATA', '[]')
              prs_data = json.loads(prs_raw) if prs_raw and prs_raw.strip() != '' else []
          except Exception as e:
              print(f"::debug::Error parseando PRs: {e}")
              prs_data = []
          prs_count = int(os.getenv('PRS_COUNT', '0'))
          issue_url = os.getenv('ISSUE_URL','')
          def current_state(num: int):
              try:
                  r = os.popen(f"gh api repos/{repo}/pulls/{num}").read()
                  data = json.loads(r)
                  st = data.get('state','open')
                  merged_at = data.get('merged_at')
                  if st == 'closed' and merged_at:
                      return 'merged'
                  return st
              except Exception:
                  return 'unknown'
          def status_badge(state: str):
              color = {'open':'brightgreen','closed':'lightgrey','merged':'purple','unknown':'blue'}.get(state,'blue')
              return f"<img src='https://img.shields.io/badge/status-{state}-{color}?style=flat-square' alt='{state}'/>"
          def label_badges(labels):
              parts = []
              for l in labels:
                  name = l.get('name','')
                  if not name:
                      continue
                  color = l.get('color','0366d6')
                  href = f"{server_url}/{repo}/pulls?q=is%3Apr+label%3A{quote_plus(name)}+author%3Aapp%2Fdependabot"
                  parts.append(f"<img src='https://img.shields.io/badge/{name.replace('-', '--')}-{color}?style=flat-square' alt='{name}' style='margin:2px'>")
              return ' '.join(parts) or 'â–'
          def days_ago(iso):
              try:
                  dt = datetime.fromisoformat(iso.replace('Z', '+00:00'))
                  now = datetime.now(timezone.utc)
                  return (now - dt).days
              except Exception:
                  return None
          def parse_title(t):
              import re
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None
          def semver_tuple(s):
              import re
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def directory_of(pr):
              meta = parse_title(pr.get('title',''))
              if meta.get('dir'):
                  return meta['dir']
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'
          def sort_key(pr):
              order = {'open':0,'merged':1,'closed':2,'unknown':3}
              st = pr.get('state','open')
              try:
                  ts = datetime.fromisoformat(pr.get('createdAt','').replace('Z','+00:00')).timestamp()
              except Exception:
                  ts = 0
              return (order.get(st,3), -ts)
          summary = []
          summary.append("# ğŸ”„ Pull Requests de Dependabot\n\n")
          if issue_url:
              summary.append(f"> ğŸ§¾ <b>Reporte consolidado:</b> <a href='{issue_url}'>{issue_url}</a>\n\n")
          if company_name:
              summary.append(f"> ğŸ¢ <b>Empresa:</b> {company_name}\n\n")
          if os.getenv('TRIGGER_DEPENDABOT_NOW','false') == 'true':
              cfg_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
              summary.append(f"> âš¡ <b>Trigger enviado</b>: se editÃ³ <a href='{cfg_url}'>dependabot.yml</a> para forzar un job de actualizaciÃ³n.\n\n")
          if prs_data and len(prs_data) > 0:
              try:
                  max_summary = int(os.getenv('MAX_SUMMARY','30'))
              except Exception:
                  max_summary = 30
              prs_sorted = sorted(prs_data, key=sort_key)
              show_list = prs_sorted[:min(prs_count, max_summary)]
              agg = {'major':0,'minor':0,'patch':0,'other':0}
              for pr in show_list:
                  meta = parse_title(pr.get('title',''))
                  if meta and meta['from'] and meta['to']:
                      agg[update_type(meta['from'], meta['to'])] += 1
              summary.append(f"Mostrando {len(show_list)} de {prs_count} PRs\n\n")
              fast = os.getenv('FAST_SUMMARY','true').lower() == 'true'
              def state_of(pr):
                  st = (pr.get('state','') or '').lower()
                  if st != 'closed':
                      return st
                  num = pr.get('number')
                  return current_state(num)
              def render_table(items, title, opened):
                  summary.append("<details open>\n" if opened else "<details>\n")
                  summary.append(f"<summary><h2>ğŸ”„ {title} ({len(items)})</h2></summary>\n\n")
                  summary.append("<table>\n")
                  summary.append("<thead>\n")
                  summary.append("<tr>\n")
                  summary.append("<th>PR</th><th>Paquete</th><th>Desde</th><th>Hasta</th><th>Dir</th><th>Estado</th><th>Labels</th><th>Edad</th>\n")
                  summary.append("</tr>\n")
                  summary.append("</thead>\n")
                  summary.append("<tbody>\n")
                  for pr in items:
                      pr_number = pr.get('number','N/A')
                      pr_url = pr.get('url','#')
                      pr_title = pr.get('title','Sin tÃ­tulo')
                      lbl_html = label_badges(pr.get('labels',[]))
                      created = pr.get('createdAt','')
                      d_ago = days_ago(created)
                      state_now = state_of(pr)
                      meta = parse_title(pr_title) or {'name':'â€”','from':'â€”','to':'â€”','dir':directory_of(pr)}
                      summary.append("<tr>\n")
                      summary.append(f"<td><a href='{pr_url}'><b>#{pr_number}</b></a></td>\n")
                      summary.append(f"<td>{meta['name']}</td>\n")
                      summary.append(f"<td>{meta['from']}</td>\n")
                      summary.append(f"<td>{meta['to']}</td>\n")
                      summary.append(f"<td><code>{meta['dir'] or '/'}</code></td>\n")
                      summary.append(f"<td>{status_badge(state_now)}</td>\n")
                      summary.append(f"<td>{lbl_html}</td>\n")
                      summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                      summary.append("</tr>\n")
                  summary.append("</tbody>\n")
                  summary.append("</table>\n\n")
                  summary.append("</details>\n\n")
              open_items, merged_items, closed_items = [], [], []
              for pr in show_list:
                  st = state_of(pr)
                  if st == 'open':
                      open_items.append(pr)
                  elif st == 'merged':
                      merged_items.append(pr)
                  elif st == 'closed':
                      closed_items.append(pr)
              render_table(open_items, 'Abiertos', True)
              render_table(merged_items, 'Fusionados', False)
              render_table(closed_items, 'Cerrados', False)
              if prs_count > len(show_list):
                  prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
                  summary.append(f"> <a href='{prs_url}'>ğŸ“‹ <b>Ver todos los PRs ({prs_count})</b></a>\n\n")
              summary.append("<details>\n")
              summary.append("<summary><h2>ğŸ“ Detalles por directorio</h2></summary>\n\n")
              groups = {}
              for pr in show_list:
                  d = directory_of(pr)
                  groups.setdefault(d or '/', []).append(pr)
              for d in sorted(groups.keys()):
                  items = groups[d]
                  summary.append(f"<h3><code>{d or '/'}</code> ({len(items)})</h3>\n")
                  summary.append("<table>\n<thead>\n<tr>\n<th>PR</th><th>Paquete</th><th>Tipo</th><th>Edad</th>\n</tr>\n</thead>\n<tbody>\n")
                  for pr in items:
                      pr_number = pr.get('number','N/A')
                      pr_url = pr.get('url','#')
                      pr_title = pr.get('title','Sin tÃ­tulo')
                      created = pr.get('createdAt','')
                      d_ago = days_ago(created)
                      meta = parse_title(pr_title) or {'name':'â€”','from':'','to':''}
                      typ = 'â€”'
                      try:
                          if meta and meta.get('from') and meta.get('to'):
                              typ = update_type(meta.get('from',''), meta.get('to',''))
                      except Exception:
                          typ = 'other'
                      typ_badge = f"<img src='https://img.shields.io/badge/update-{typ}-informational?style=flat-square" alt='{typ}'/>"
                      summary.append("<tr>\n")
                      summary.append(f"<td><a href='{pr_url}'>#{pr_number}</a></td>\n")
                      summary.append(f"<td>{meta['name']}</td>\n")
                      summary.append(f"<td>{typ_badge}</td>\n")
                      summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                      summary.append("</tr>\n")
                  summary.append("</tbody>\n</table>\n\n")
              summary.append("</details>\n\n")
          else:
              summary.append("> â„¹ï¸ No hay PRs activos de Dependabot en este momento.\n\n")
          summary.append("<details>\n")
          summary.append("<summary><h2>âš™ï¸ CÃ³mo activar manualmente</h2></summary>\n\n")
          dep_graph = f"{server_url}/{repo}/network/dependencies"
          prs_link = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          summary.append("1) Ve a <b>Insights â†’ Dependency graph â†’ Dependabot</b>\n")
          summary.append(f"2) En <b>Recent update jobs</b>, pulsa <b>Check for updates</b> â€¢ <a href='{dep_graph}'>Acceder</a>\n")
          summary.append(f"3) Revisa nuevos PRs: <a href='{prs_link}'>Listado de PRs de Dependabot</a>\n\n")
          summary.append("</details>\n\n")
          summary.append("<details>\n")
          summary.append("<summary><h2>ğŸ“„ Reportes Exportados</h2></summary>\n\n")
          run_id = os.getenv('GITHUB_RUN_ID','')
          if run_id:
              run_link = f"{server_url}/{repo}/actions/runs/{run_id}"
              summary.append(f"- PDF/HTML: <a href='{run_link}'>Descargar desde el run</a>\n\n")
          summary.append("</details>\n\n")
          summary.append("<details>\n")
          summary.append("<summary><h2>ğŸ”— Enlaces Ãštiles</h2></summary>\n\n")
          config_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
          security_url = f"{server_url}/{repo}/settings/security_analysis"
          insights_url = f"{server_url}/{repo}/network/dependencies"
          labels_url = f"{server_url}/{repo}/labels"
          prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          advisories_url = f"{server_url}/{repo}/security/dependabot"
          doc_url = f"{server_url}/{repo}/blob/main/docs/security/dependency-check/dependabot-report.md"
          summary.append(f"- ğŸ“ <a href='{config_url}'><b>Ver ConfiguraciÃ³n</b></a>\n")
          summary.append(f"- ğŸ›¡ï¸ <a href='{security_url}'><b>Security Settings</b></a>\n")
          summary.append(f"- ğŸ“Š <a href='{insights_url}'><b>Dependency Graph</b></a>\n")
          summary.append(f"- ğŸ·ï¸ <a href='{labels_url}'><b>Gestionar Labels</b></a>\n")
          summary.append(f"- ğŸ”„ <a href='{prs_url}'><b>PRs de Dependabot</b></a>\n")
          summary.append(f"- ğŸš¨ <a href='{advisories_url}'><b>Security Alerts</b></a>\n")
          summary.append(f"- ğŸ“˜ <a href='{doc_url}'><b>DocumentaciÃ³n del workflow reusable</b></a>\n\n")
          summary.append("</details>\n\n")
          summary.append("<details>\n")
          summary.append("<summary><h2>â„¹ï¸ InformaciÃ³n</h2></summary>\n\n")
          summary.append("- ğŸ” DetecciÃ³n y resumen inteligente de PRs\n")
          summary.append("- ğŸ·ï¸ Badges de estado y labels\n")
          summary.append("- â±ï¸ Edad de PRs y ordenamiento\n")
          summary.append("- ğŸ“ SecciÃ³n por directorio\n")
          summary.append("- ğŸ”— Enlaces Ãºtiles de UI\n\n")
          summary.append("</details>\n\n")
          timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          workflow_url = f"{server_url}/jersonmartinez/reusable-workflows"
          summary.append(f"<sub>ğŸ¤– Generado por <a href='{workflow_url}'><b>Reusable Workflows</b></a> â€¢ {timestamp}</sub>\n")
          with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
              f.write(''.join(summary))
          print("âœ… Summary generado correctamente")
          print(f"ğŸ“Š PRs detectados: {prs_count}")
          PY_EOF
          fi
          python3 "$SCRIPT_PATH"

      - name: ğŸ’¾ Subir artifact de depuraciÃ³n
        if: ${{ inputs.upload_debug_artifact }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-debug
          path: docs/output.txt

  report_html:
    name: Generate HTML report
    runs-on: ubuntu-latest
    needs: [configure]
    if: ${{ inputs.generate_html_report }}
    steps:
      - name: ğŸš€ Checkout Repository
        uses: actions/checkout@v4
      - name: ğŸ§¾ Generar HTML del reporte (modular)
        uses: ./.github/actions/dependabot-html-report
        with:
          prs_data: ${{ needs.configure.outputs.prs_data }}
          alerts_data: ${{ needs.configure.outputs.alerts_data }}
          output_path: docs/${{ inputs.html_report_name }}
          issue_url: ${{ needs.configure.outputs.issue_url }}
          company_name: ${{ inputs.company_name }}
          logo_url: ${{ inputs.logo_url }}
      - name: â™»ï¸ Guardar HTML en cache
        uses: actions/cache/save@v4
        with:
          path: docs/${{ inputs.html_report_name }}
          key: dep-report-${{ github.run_id }}-html

      - name: ğŸ“¤ Subir HTML como artefacto (sin PDF)
        if: ${{ inputs.generate_html_report && !inputs.generate_pdf_report }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-reportes
          path: docs/${{ inputs.html_report_name }}
          if-no-files-found: warn

  report_pdf:
    name: Generate PDF report
    runs-on: ubuntu-latest
    needs: [configure]
    if: ${{ inputs.generate_pdf_report }}
    outputs:
      pdf_created: ${{ steps.generate_pdf.outputs.created }}
    steps:
      - name: ğŸš€ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ†” Determine Workflow Ref
        id: workflow_ref
        run: |
          WORKFLOW_REF="${{ github.workflow_ref }}"
          if [ -z "$WORKFLOW_REF" ]; then
            echo "ref=${{ github.ref }}" >> $GITHUB_OUTPUT
            echo "repo=${{ github.repository }}" >> $GITHUB_OUTPUT
          else
            REF=$(echo "$WORKFLOW_REF" | cut -d'@' -f2)
            REPO=$(echo "$WORKFLOW_REF" | cut -d'/' -f1,2)
            echo "ref=$REF" >> $GITHUB_OUTPUT
            echo "repo=$REPO" >> $GITHUB_OUTPUT
          fi

      - name: ğŸ“¥ Checkout Scripts
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.workflow_ref.outputs.repo }}
          ref: ${{ steps.workflow_ref.outputs.ref }}
          path: .reusable-scripts

      - name: ğŸ•µï¸ Debug Scripts Existence
        run: |
          echo "Listing .reusable-scripts content:"
          ls -R .reusable-scripts || echo ".reusable-scripts not found"

      - name: ğŸ“„ Generar PDF del reporte (parallel)
        id: generate_pdf
        env:
          PRS_DATA: ${{ needs.configure.outputs.prs_data }}
          PDF_PATH: docs/${{ inputs.pdf_report_name }}
          REPO: ${{ github.repository }}
          GH_TOKEN: ${{ github.token }}
          ISSUE_URL: ${{ needs.configure.outputs.issue_url }}
        run: |
          sudo apt-get update -y || true
          sudo apt-get install -y libcairo2 libcairo2-dev libpango1.0-dev libgdk-pixbuf2.0-dev pkg-config || true
          python3 -m pip install --user reportlab || true
          python3 -m pip install --user svglib lxml cssselect2 tinycss2 || true
          export PYTHONPATH="$(python3 -c 'import site; print(site.getusersitepackages())')${PYTHONPATH:+:$PYTHONPATH}"
          
          SCRIPT_PATH=".reusable-scripts/scripts/generate_pdf.py"
          if [ ! -f "$SCRIPT_PATH" ]; then
            if [ -f "scripts/generate_pdf.py" ]; then
              SCRIPT_PATH="scripts/generate_pdf.py"
            else
              echo "::error::Script not found at $SCRIPT_PATH"
              exit 1
            fi
          fi
          python3 "$SCRIPT_PATH"
