name: Setup Dependabot

on:
  workflow_call:
    inputs:

      create_issue:
        required: false
        type: boolean
        default: true
        description: 'Crear issue de reporte de hallazgos'

      issue_title:
        required: false
        type: string
        default: 'Reporte Dependabot: ${date}'
        description: 'T√≠tulo del issue; use ${date} para fecha UTC'

      issue_labels:
        required: false
        type: string
        default: 'dependabot-report'
        description: 'Labels para el issue, separados por coma'

      close_dependabot_prs:
        required: false
        type: boolean
        default: true
        description: 'Cerrar los PRs de Dependabot tras crear el issue'

      wait_minutes:
        required: false
        type: number
        default: 5
        description: 'Minutos m√°ximos para esperar PRs nuevos de Dependabot'

      create_missing_labels:
        required: false
        type: boolean
        default: false
        description: 'Crear labels faltantes antes de generar configuraci√≥n'

      create_issue_if_empty:
        required: false
        type: boolean
        default: true
        description: 'Crear issue aunque no existan PRs detectados'

      upload_debug_artifact:
        required: false
        type: boolean
        default: true
        description: 'Subir docs/output.txt como artifact de depuraci√≥n'

      trigger_dependabot_now:
        required: false
        type: boolean
        default: false
        description: 'Forzar ejecuci√≥n editando .github/dependabot.yml (cambio sin impacto)'

      dependabot_config_path:
        required: false
        type: string
        default: '.github/dependabot.yml'
        description: 'Ruta del archivo dependabot.yml existente'

      dependabot_logins:
        required: false
        type: string
        default: 'dependabot,dependabot[bot],app/dependabot'
        description: 'Lista de logins (coma) que se consideran Dependabot'

      poll_interval_seconds:
        required: false
        type: number
        default: 30
        description: 'Intervalo de polling en segundos'

      dry_run_close:
        required: false
        type: boolean
        default: false
        description: 'No cerrar PRs, solo reportar'

      skip_close_labels:
        required: false
        type: string
        default: ''
        description: 'Labels (coma) que evitan cierre del PR'

      max_prs_in_summary:
        required: false
        type: number
        default: 30
        description: 'M√°ximo de PRs listados en el summary'

      # Exporta reporte en PDF como artifact del run
      generate_pdf_report:
        required: false
        type: boolean
        default: false
        description: 'Generar y subir PDF del reporte de PRs'

      # Nombre del archivo PDF a generar
      pdf_report_name:
        required: false
        type: string
        default: 'dependabot-report.pdf'
        description: 'Nombre del archivo PDF generado'

      # Exporta reporte en HTML navegable como artifact
      generate_html_report:
        required: false
        type: boolean
        default: true
        description: 'Generar y subir HTML del reporte de PRs'

      # Nombre del archivo HTML a generar
      html_report_name:
        required: false
        type: string
        default: 'dependabot-report.html'
        description: 'Nombre del archivo HTML generado'

jobs:
  configure:
    name: Configuring
    runs-on: ubuntu-latest
    timeout-minutes: 45
    concurrency:
      group: dependabot-report
      cancel-in-progress: true
    permissions:
      contents: write
      issues: write
      pull-requests: write

    steps:
      - name: üöÄ Checkout Repository
        uses: actions/checkout@v4

      - name: üïí Marcar inicio
        if: false
        run: echo "skip"

      - name: üß™ Preparar logs de depuraci√≥n
        run: |
          mkdir -p docs
          printf "[START] Dependabot report debug at %s\n" "$(date -u +'%Y-%m-%d %H:%M:%SZ')" > docs/output.txt

      - name: ‚ö° Trigger Dependabot (opcional)
        if: ${{ inputs.trigger_dependabot_now }}
        env:
          GH_TOKEN: ${{ github.token }}
          CFG_PATH: ${{ inputs.dependabot_config_path }}
        run: |
          set -e
          if [ ! -f "$CFG_PATH" ]; then
            echo "::warning::No existe $CFG_PATH. No se puede forzar ejecuci√≥n"
            exit 0
          fi
          TS=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          echo "# trigger: $TS" >> "$CFG_PATH"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$CFG_PATH"
          if git diff --cached --quiet; then
            echo "Sin cambios en $CFG_PATH"
          else
            git commit -m "chore(dependabot): trigger run at $TS"
            git push || echo "::warning::No se pudo pushear cambios (verificar permisos)"
            echo "Triggered Dependabot via config change at $TS" >> docs/output.txt
          fi

      - name: üîç Validate Labels
        id: validate_labels
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          cat > /tmp/validate_labels.py << 'SCRIPT_EOF'
          import json, os, subprocess, sys
          from collections import defaultdict

          repo = os.getenv('GITHUB_REPOSITORY')

          try:
              result = subprocess.run(
                  ['gh', 'label', 'list', '--repo', repo, '--json', 'name,color,description', '--limit', '1000'],
                  capture_output=True, text=True, check=True
              )
              labels_data = json.loads(result.stdout)
              existing_labels = {label['name'].lower(): label for label in labels_data}
          except Exception as e:
              print(f"::error::No se pudieron obtener los labels: {e}")
              existing_labels = {}

          try:
              ecosystems = json.loads('''${{ inputs.ecosystems }}''')
          except json.JSONDecodeError as e:
              print(f"::error::Error al parsear ecosistemas: {e}")
              sys.exit(1)

          missing_by_ecosystem = defaultdict(list)
          valid_by_ecosystem = defaultdict(list)
          filtered_ecosystems = []
          all_missing = set()

          for eco in ecosystems:
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              valid_labels = []
              
              for label in labels:
                  if label.lower() in existing_labels:
                      valid_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      valid_labels.append(label)
                  else:
                      missing_by_ecosystem[f"{eco['ecosystem']}|{eco['directory']}"].append(label)
                      all_missing.add(label)

              # Crear ecosistema filtrado con SOLO labels v√°lidos
              filtered_eco = eco.copy()
              filtered_eco['labels'] = ','.join(valid_labels)
              filtered_ecosystems.append(filtered_eco)

          # Generar outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"missing_labels={','.join(sorted(all_missing))}\n")
              f.write(f"missing_count={len(all_missing)}\n")
              f.write(f"valid_count={sum(len(v) for v in valid_by_ecosystem.values())}\n")
              f.write(f"has_missing={'true' if all_missing else 'false'}\n")
              
              # Exportar ecosistemas filtrados
              filtered_json = json.dumps(filtered_ecosystems)
              f.write(f"filtered_ecosystems<<EOF\n")
              f.write(f"{filtered_json}\n")
              f.write(f"EOF\n")

          # Guardar datos para el summary
          with open('/tmp/validation_data.json', 'w') as f:
              json.dump({
                  'missing_by_ecosystem': dict(missing_by_ecosystem),
                  'valid_by_ecosystem': dict(valid_by_ecosystem),
                  'existing_labels': existing_labels
              }, f)

          if all_missing:
              print(f"::warning title=Labels Faltantes::Se encontraron {len(all_missing)} labels sin configurar. Ser√°n omitidos del archivo generado.")
              for label in sorted(all_missing):
                  print(f"  ‚ö†Ô∏è {label}")
          else:
              print("::notice title=Validaci√≥n Exitosa::Todos los labels est√°n configurados correctamente")
          
          print(f"\nüìä Resumen:")
          print(f"  ‚úÖ Labels v√°lidos: {sum(len(v) for v in valid_by_ecosystem.values())}")
          print(f"  ‚ö†Ô∏è Labels faltantes: {len(all_missing)}")
          print(f"  üì¶ Ecosistemas: {len(ecosystems)}")
          SCRIPT_EOF

          python3 /tmp/validate_labels.py

      - name: üè∑Ô∏è Crear labels faltantes
        if: false
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          MISSING="${{ steps.validate_labels.outputs.missing_labels }}"
          REPO="$GITHUB_REPOSITORY"
          IFS=',' read -ra LABELS <<< "$MISSING"
          for l in "${LABELS[@]}"; do
            [ -z "$l" ] && continue
            gh label create "$l" --repo "$REPO" --color 0366d6 --description "Auto-creado para Dependabot" || true
            echo "Creado label: $l"
          done

      - name: üè∑Ô∏è Crear labels del Issue faltantes
        if: ${{ inputs.issue_labels != '' && inputs.create_missing_labels }}
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
        run: |
          REPO="$GITHUB_REPOSITORY"
          EXISTING=$(gh label list --repo "$REPO" --json name --jq '.[].name')
          declare -A MAP
          for n in $EXISTING; do MAP[$n]=1; done
          IFS=',' read -ra LBS <<< "$ISSUE_LABELS"
          for l in "${LBS[@]}"; do
            NAME=$(echo "$l" | xargs)
            [ -z "$NAME" ] && continue
            if [ -z "${MAP[$NAME]}" ]; then
              gh label create "$NAME" --repo "$REPO" --color 6f42c1 --description "Auto-creado para reporte" || true
              echo "Creado label de Issue: $NAME"
            fi
          done

      - name: üìù Generate Dependabot Config
        if: false
        env:
          FILTERED_ECOSYSTEMS: ${{ steps.validate_labels.outputs.filtered_ecosystems }}
        run: |
          cat > /tmp/generate_config.py << 'SCRIPT_EOF'
          import json, os, sys

          try:
              ecosystems = json.loads(os.getenv('FILTERED_ECOSYSTEMS', '[]'))
          except json.JSONDecodeError as e:
              print(f"::error::JSON inv√°lido: {e}")
              sys.exit(1)

          if not ecosystems:
              print("::error::No hay ecosistemas para configurar")
              sys.exit(1)

          schedule = '${{ inputs.schedule }}'
          pr_limit = ${{ inputs.pr_limit }}
          target_branch = '${{ inputs.target_branch }}'

          config = {'version': 2, 'updates': []}

          for eco in ecosystems:
              update = {
                  'package-ecosystem': eco['ecosystem'],
                  'directory': eco['directory'],
                  'schedule': {'interval': schedule},
                  'open-pull-requests-limit': eco.get('pr_limit', pr_limit)
              }

              if target_branch:
                  update['target-branch'] = target_branch

              # Los labels ya est√°n filtrados (solo v√°lidos)
              labels = [l.strip() for l in eco.get('labels', '').split(',') if l.strip()]
              if labels:
                  update['labels'] = labels

              prefix = eco.get('prefix', '').strip()
              if prefix:
                  update['commit-message'] = {'prefix': prefix}

              config['updates'].append(update)

          import yaml
          os.makedirs('.github', exist_ok=True)

          with open('.github/dependabot.yml', 'w') as f:
            yaml.dump(config, f, sort_keys=False, default_flow_style=False, indent=2)

          print("‚úÖ Configuraci√≥n generada exitosamente (solo con labels v√°lidos)")

          with open('.github/dependabot.yml', 'r') as f:
              content = f.read()
              print("\nüìÑ Contenido generado:")
              print(content)
          SCRIPT_EOF

          python3 /tmp/generate_config.py

      - name: üíæ Commit Changes
        id: commit
        if: false
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          if git diff --quiet .github/dependabot.yml; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "üìå Sin cambios - La configuraci√≥n est√° actualizada"
          else
            git add .github/dependabot.yml
            git commit -m "chore: update dependabot configuration"
            git push
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "commit_sha=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
            echo "‚úÖ Cambios commiteados y pusheados"
          fi

      - name: üîÑ Detect Dependabot PRs
        id: detect_prs
        env:
          GH_TOKEN: ${{ github.token }}
          WAIT_MINUTES: ${{ inputs.wait_minutes }}
          POLL_INTERVAL: ${{ inputs.poll_interval_seconds }}
          DEP_LOGINS: ${{ inputs.dependabot_logins }}
        run: |
          cat > /tmp/detect_prs.py << 'SCRIPT_EOF'
          # Poll de PRs abiertos usando la API de GitHub v√≠a gh CLI.
          # Filtra por autores de Dependabot (varios formatos) y escribe logs de depuraci√≥n.
          import json, os, subprocess, time
          
          wait_minutes = int(os.getenv('WAIT_MINUTES', '10'))
          poll_interval = int(os.getenv('POLL_INTERVAL', '30'))
          repo = os.getenv('GITHUB_REPOSITORY')
          debug_path = os.path.join('docs','output.txt')
          dep_logins = [s.strip() for s in os.getenv('DEP_LOGINS','dependabot,dependabot[bot],app/dependabot').split(',') if s.strip()]
          
          def log(msg):
              try:
                  with open(debug_path,'a') as df:
                      df.write(msg + "\n")
              except Exception:
                  pass
          
          def list_prs_api():
            # Obtiene PRs abiertos y filtra por login de usuario
            try:
              args = [
                'gh','api','repos/'+repo+'/pulls',
                '--method','GET',
                '--field','state=open',
                '--field','per_page=100',
                '--paginate'
              ]
              result = subprocess.run(args, capture_output=True, text=True)
              if result.returncode == 0 and result.stdout.strip():
                data = json.loads(result.stdout)
                filtered = []
                for pr in data:
                  login = (pr.get('user',{}) or {}).get('login','')
                  if login in dep_logins:
                    filtered.append({
                      'number': pr.get('number'),
                      'title': pr.get('title'),
                      'url': pr.get('html_url'),
                      'labels': pr.get('labels',[]),
                      'createdAt': pr.get('created_at',''),
                      'headRefName': (pr.get('head',{}) or {}).get('ref',''),
                      'state': pr.get('state','')
                    })
                return filtered
              log(f"list_prs_api non-0 returncode: {result.returncode} stderr={result.stderr.strip()}")
              return []
            except Exception as e:
              log(f"list_prs_api exception: {e}")
              return []
          
          prs = list_prs_api()
          log(f"Initial PRs count: {len(prs)}")
          if prs:
              for pr in prs:
                  log(f"PR #{pr['number']} - {pr['title']} - {pr['url']}")
          
          deadline = time.time() + wait_minutes*60
          while len(prs) == 0 and time.time() < deadline:
              time.sleep(poll_interval)
              prs = list_prs_api()
              log(f"Polling... PRs count: {len(prs)}")
          
          # Export outputs
          with open(os.environ['GITHUB_OUTPUT'],'a') as f:
              # Exporta resultados para usar en pasos posteriores
              f.write('prs_data<<EOF\n')
              f.write(json.dumps(prs))
              f.write('\nEOF\n')
              f.write(f"prs_count={len(prs)}\n")
          
          print(f"üìä PRs detectados: {len(prs)}")
          SCRIPT_EOF
          
          python3 /tmp/detect_prs.py

      - name: üßæ Crear Issue de Reporte
        id: create_issue
        if: ${{ inputs.create_issue && (steps.detect_prs.outputs.prs_count != '0' || inputs.create_issue_if_empty) }}
        env:
          GH_TOKEN: ${{ github.token }}
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          ISSUE_TITLE_TPL: ${{ inputs.issue_title }}
          ISSUE_LABELS: ${{ inputs.issue_labels }}
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
        run: |
          cat > /tmp/create_issue.py << 'SCRIPT_EOF'
          # Construye el cuerpo del Issue con tabla resumen y detalles.
          # Reutiliza el Issue si ya existe con el mismo t√≠tulo.
          import json, os, re, subprocess
          from datetime import datetime, timezone
          
          debug_path = os.path.join('docs','output.txt')
          
          def log(msg):
              try:
                  with open(debug_path,'a') as df:
                      df.write(msg + "\n")
              except Exception:
                  pass
          
          def pr_details(num, repo):
              # Recupera el cuerpo del PR para incluir un snippet en el Issue
              try:
                  r = subprocess.run(['gh','pr','view',str(num),'--repo',repo,'--json','body'], capture_output=True, text=True)
                  if r.returncode == 0:
                      data = json.loads(r.stdout)
                      return data.get('body','')
                  return ''
              except Exception:
                  return ''
          
          def parse_title(t):
              # Extrae paquete, versiones y directorio del t√≠tulo t√≠pico de Dependabot
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None
          
          def semver_tuple(s):
              # Convierte versi√≥n a tupla (major, minor, patch)
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          
          def update_type(f, t):
              # Determina tipo de actualizaci√≥n por comparaci√≥n sem√°ntica
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          
          def build_body(prs, date, repo):
            # Construye el contenido Markdown detallado del Issue
            lines = []
            run_id = os.getenv('RUN_ID','')
            server_url = os.getenv('SERVER_URL','https://github.com')
            if run_id:
                lines.append(f"**Descargar reportes (PDF/HTML):** {server_url}/{repo}/actions/runs/{run_id}\n\n")
            lines.append(f"### Reporte de actualizaciones ({date})\n")
            if prs:
                agg = {'major':0,'minor':0,'patch':0,'other':0}
                lines.append("\n| PR | Paquete | Desde | Hasta | Dir | Labels |\n")
                lines.append("|:--:|:-------|:-----:|:-----:|:---:|:------:|\n")
                for pr in prs:
                    num = pr.get('number')
                    url = pr.get('url')
                    title_pr = pr.get('title','')
                    meta = parse_title(title_pr) or {'name':'‚Äî','from':'‚Äî','to':'‚Äî','dir':''}
                    labels_pr = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or '‚Äî'
                    lines.append(f"| [#{num}]({url}) | {meta['name']} | {meta['from']} | {meta['to']} | {meta['dir']} | {labels_pr} |\n")
                    if meta['from'] != '‚Äî' and meta['to'] != '‚Äî':
                        agg[update_type(meta['from'], meta['to'])] += 1
                lines.append("\n#### Resumen por tipo\n")
                lines.append(f"- Major: {agg['major']}\n- Minor: {agg['minor']}\n- Patch: {agg['patch']}\n- Other: {agg['other']}\n")
                lines.append("\n#### Detalles\n")
                for pr in prs:
                    num = pr.get('number')
                    url = pr.get('url')
                    title_pr = pr.get('title','')
                    body = pr_details(num, repo)
                    snippet = (body or '').strip()
                    if len(snippet) > 1200:
                        snippet = snippet[:1200] + '‚Ä¶'
                    lines.append(f"- [#{num}]({url}) {title_pr}\n")
                    if snippet:
                        lines.append(f"  \n  {snippet}\n")
            else:
                lines.append("\nNo se encontraron PRs abiertos de Dependabot en este momento.\n")
            return ''.join(lines)

          def find_existing_issue(title, repo):
              # Busca un Issue abierto con t√≠tulo id√©ntico para evitar duplicados
              try:
                  r = subprocess.run(['gh','issue','list','--repo',repo,'--state','open','--limit','100','--json','number,title,url'], capture_output=True, text=True)
                  if r.returncode == 0 and r.stdout.strip():
                      items = json.loads(r.stdout)
                      for it in items:
                          if it.get('title','') == title:
                              return it.get('url','')
                  return ''
              except Exception:
                  return ''
          
          def main():
            # Orquesta la creaci√≥n o reutilizaci√≥n del Issue
            prs_raw = os.getenv('PRS_DATA','[]')
            prs = json.loads(prs_raw) if prs_raw.strip() else []
            date = datetime.now(timezone.utc).strftime('%Y-%m-%d')
            title_tpl = os.getenv('ISSUE_TITLE_TPL','Reporte Dependabot: ${date}')
            title = title_tpl.replace('${date}', date)
            labels = [l.strip() for l in os.getenv('ISSUE_LABELS','').split(',') if l.strip()]
            repo = os.getenv('GITHUB_REPOSITORY')
            existing = find_existing_issue(title, repo)
            if existing:
                with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                    f.write(f"issue_url={existing}\n")
                log(f"Issue existente reutilizado: {existing}")
                print(f"üßæ Issue reutilizado: {existing}")
                return
            body = build_body(prs, date, repo)
            cmd = ['gh','issue','create','--repo',repo,'--title',title,'--body',body]
            for l in labels:
                cmd += ['--label', l]
            result = subprocess.run(cmd, capture_output=True, text=True)
            url = ''
            if result.returncode == 0:
                for line in result.stdout.splitlines():
                    if line.strip().startswith('https://'):
                        url = line.strip()
                        break
            else:
                log(f"Fallo al crear issue con labels. stderr: {result.stderr.strip()}")
                result2 = subprocess.run(['gh','issue','create','--repo',repo,'--title',title,'--body',body], capture_output=True, text=True)
                if result2.returncode == 0:
                    for line in result2.stdout.splitlines():
                        if line.strip().startswith('https://'):
                            url = line.strip()
                            break
                else:
                    log(f"Intento sin labels tambi√©n fall√≥. stderr: {result2.stderr.strip()}")
            with open(os.environ['GITHUB_OUTPUT'],'a') as f:
                f.write(f"issue_url={url}\n")
            log(f"Issue title: {title}")
            log(f"Issue created: {url if url else 'N/A'}")
            print(f"üßæ Issue creado: {url if url else 'N/A'}")
          
          if __name__ == '__main__':
              main()
          SCRIPT_EOF
          
          python3 /tmp/create_issue.py

      - name: üìÑ Generar PDF del reporte
        id: generate_pdf
        if: ${{ inputs.generate_pdf_report }}
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PDF_PATH: docs/${{ inputs.pdf_report_name }}
          REPO: ${{ github.repository }}
        run: |
          python3 -m pip install --user reportlab || true
          export PYTHONPATH="$(python3 -c 'import site; print(site.getusersitepackages())')${PYTHONPATH:+:$PYTHONPATH}"
          python3 - << 'PY'
          # Genera un PDF con √≠ndice y m√©tricas por tipo, directorio y ecosistema
          import json, os
          from datetime import datetime, timezone
          created = False
          try:
              from reportlab.lib.pagesizes import A4
              from reportlab.lib import colors
              from reportlab.lib.styles import getSampleStyleSheet
              from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
          except Exception as e:
              # Fallback: sin reportlab, evita fallo y marca no creado
              out = os.environ.get('GITHUB_OUTPUT')
              if out:
                  with open(out,'a') as f:
                      f.write('created=false\n')
              print(f"Reportlab no disponible: {e}. Saltando generaci√≥n de PDF.")
              raise SystemExit(0)
          try:
              prs = json.loads(os.getenv('PRS_DATA','[]'))
          except Exception:
              prs = []
          pdf_path = os.getenv('PDF_PATH','docs/dependabot-report.pdf')
          os.makedirs(os.path.dirname(pdf_path), exist_ok=True)
          styles = getSampleStyleSheet()
          doc = SimpleDocTemplate(pdf_path, pagesize=A4)
          flow = []
          title = Paragraph('Reporte de Dependabot', styles['Title'])
          flow.append(title)
          flow.append(Spacer(1,12))
          ts = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          flow.append(Paragraph(f'Generado: {ts}', styles['Normal']))
          flow.append(Spacer(1,12))

          import re
          def parse_title(t):
              # Extrae metadatos del t√≠tulo t√≠pico de Dependabot
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return {'name':'‚Äî','from':'','to':'','dir':''}
          def semver_tuple(s):
              nums = [int(x) for x in re.findall(r"\d+", s)[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n (major/minor/patch/other)
              if not f or not t:
                  return 'other'
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def directory_of(pr):
              # Detecta directorio desde el t√≠tulo o la rama de Dependabot
              meta = parse_title(pr.get('title',''))
              if meta.get('dir'):
                  return meta['dir']
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'
          def ecosystem_of(pr):
              # Extrae ecosistema desde la rama (npm_and_yarn ‚Üí npm, etc.)
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+1:
                          eco = parts[idx+1]
                          return 'npm' if eco == 'npm_and_yarn' else eco
                  except Exception:
                      pass
              return 'unknown'

          total_agg = {'major':0,'minor':0,'patch':0,'other':0}
          dir_agg = {}
          eco_agg = {}
          for pr in prs:
              meta = parse_title(pr.get('title',''))
              typ = update_type(meta.get('from',''), meta.get('to',''))
              total_agg[typ] = total_agg.get(typ,0)+1
              d = directory_of(pr)
              dir_agg.setdefault(d, {'major':0,'minor':0,'patch':0,'other':0})
              dir_agg[d][typ] += 1
              e = ecosystem_of(pr)
              eco_agg.setdefault(e, {'major':0,'minor':0,'patch':0,'other':0})
              eco_agg[e][typ] += 1

          flow.append(Paragraph('√çndice', styles['Heading2']))
          # Tabla de contenidos para navegaci√≥n r√°pida del documento
          flow.append(Paragraph('1. Resumen general', styles['Normal']))
          flow.append(Paragraph('2. M√©tricas por directorio', styles['Normal']))
          flow.append(Paragraph('3. M√©tricas por ecosistema', styles['Normal']))
          flow.append(Paragraph('4. Listado de PRs', styles['Normal']))
          flow.append(Spacer(1,12))

          flow.append(Paragraph('Resumen general', styles['Heading2']))
          flow.append(Spacer(1,6))
          data_summary = [['Tipo','Cantidad'],['major',total_agg['major']],['minor',total_agg['minor']],['patch',total_agg['patch']],['other',total_agg['other']]]
          tbl_sum = Table(data_summary, repeatRows=1)
          tbl_sum.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_sum)
          flow.append(Spacer(1,12))

          flow.append(Paragraph('M√©tricas por directorio', styles['Heading2']))
          flow.append(Spacer(1,6))
          data_dir = [['Directorio','major','minor','patch','other']]
          for d in sorted(dir_agg.keys()):
              row = [d, dir_agg[d]['major'], dir_agg[d]['minor'], dir_agg[d]['patch'], dir_agg[d]['other']]
              data_dir.append(row)
          tbl_dir = Table(data_dir, repeatRows=1)
          tbl_dir.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_dir)
          flow.append(Spacer(1,12))

          flow.append(Paragraph('M√©tricas por ecosistema', styles['Heading2']))
          flow.append(Spacer(1,6))
          data_eco = [['Ecosistema','major','minor','patch','other']]
          for e in sorted(eco_agg.keys()):
              row = [e, eco_agg[e]['major'], eco_agg[e]['minor'], eco_agg[e]['patch'], eco_agg[e]['other']]
              data_eco.append(row)
          tbl_eco = Table(data_eco, repeatRows=1)
          tbl_eco.setStyle(TableStyle([('BACKGROUND',(0,0),(-1,0),colors.lightgrey),('GRID',(0,0),(-1,-1),0.5,colors.grey)]))
          flow.append(tbl_eco)
          flow.append(Spacer(1,12))

          flow.append(Paragraph('Listado de PRs', styles['Heading2']))
          flow.append(Spacer(1,6))
          data = [['PR','Paquete','Desde','Hasta','Dir','Estado','Labels','Creado']]
          for pr in prs:
              num = pr.get('number','')
              title = pr.get('title','')
              meta = parse_title(title)
              created = pr.get('createdAt','')
              try:
                  created_fmt = datetime.fromisoformat(created.replace('Z','+00:00')).strftime('%Y-%m-%d')
              except Exception:
                  created_fmt = 'N/A'
              labels = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or '‚Äî'
              state = pr.get('state','open')
              d = meta.get('dir') or directory_of(pr)
              data.append([f"#{num}", meta['name'], meta['from'], meta['to'], d, state, labels, created_fmt])
          table = Table(data, repeatRows=1)
          table.setStyle(TableStyle([
              ('BACKGROUND',(0,0),(-1,0),colors.lightgrey),
              ('TEXTCOLOR',(0,0),(-1,0),colors.black),
              ('GRID',(0,0),(-1,-1),0.5,colors.grey),
              ('FONTNAME',(0,0),(-1,0),'Helvetica-Bold'),
              ('ALIGN',(0,0),(-1,-1),'LEFT'),
              ('VALIGN',(0,0),(-1,-1),'MIDDLE'),
          ]))
          flow.append(table)
          doc.build(flow)
          created = True
          out = os.environ.get('GITHUB_OUTPUT')
          if out:
              with open(out,'a') as f:
                  f.write('created=true\n')
          print(f"PDF generado en {pdf_path}")
          PY

      - name: üßæ Generar HTML del reporte
        if: ${{ inputs.generate_html_report }}
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          HTML_PATH: docs/${{ inputs.html_report_name }}
        run: |
          python3 - << 'PY'
          # Genera un HTML navegable con √≠ndice y m√©tricas agregadas
          import json, os
          from datetime import datetime, timezone
          import re
          try:
              prs = json.loads(os.getenv('PRS_DATA','[]'))
          except Exception:
              prs = []
          html_path = os.getenv('HTML_PATH','docs/dependabot-report.html')
          os.makedirs(os.path.dirname(html_path), exist_ok=True)
          def parse_title(t):
              # Extrae paquete, versiones y directorio del t√≠tulo
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return {'name':'‚Äî','from':'','to':'','dir':''}
          def semver_tuple(s):
              nums = [int(x) for x in re.findall(r"\d+", s)[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)
          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n
              if not f or not t:
                  return 'other'
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'
          def directory_of(pr):
              # Obtiene directorio principal del cambio
              meta = parse_title(pr.get('title',''))
              if meta.get('dir'):
                  return meta['dir']
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'
          def ecosystem_of(pr):
              # Detecta ecosistema desde la rama
              ref = pr.get('headRefName','')
              if '/' in ref:
                  parts = ref.split('/')
                  try:
                      idx = parts.index('dependabot')
                      if idx >= 0 and len(parts) > idx+1:
                          eco = parts[idx+1]
                          return 'npm' if eco == 'npm_and_yarn' else eco
                  except Exception:
                      pass
              return 'unknown'
          total_agg = {'major':0,'minor':0,'patch':0,'other':0}
          dir_agg = {}
          eco_agg = {}
          rows = []
          for pr in prs:
              meta = parse_title(pr.get('title',''))
              typ = update_type(meta.get('from',''), meta.get('to',''))
              total_agg[typ] = total_agg.get(typ,0)+1
              d = directory_of(pr)
              dir_agg.setdefault(d, {'major':0,'minor':0,'patch':0,'other':0})
              dir_agg[d][typ] += 1
              e = ecosystem_of(pr)
              eco_agg.setdefault(e, {'major':0,'minor':0,'patch':0,'other':0})
              eco_agg[e][typ] += 1
              labels = ', '.join([l.get('name','') for l in pr.get('labels',[])]) or '‚Äî'
              created = pr.get('createdAt','')
              try:
                  created_fmt = datetime.fromisoformat(created.replace('Z','+00:00')).strftime('%Y-%m-%d')
              except Exception:
                  created_fmt = 'N/A'
              rows.append({'num': pr.get('number',''), 'name': meta['name'], 'from': meta['from'], 'to': meta['to'], 'dir': d, 'state': pr.get('state','open'), 'labels': labels, 'created': created_fmt, 'url': pr.get('url','#')})
          ts = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          html = []
          html.append('<!doctype html><html><head><meta charset="utf-8"><title>Reporte Dependabot</title><style>body{font-family:Arial,sans-serif;padding:20px}table{border-collapse:collapse;width:100%}th,td{border:1px solid #ddd;padding:8px}th{background:#f2f2f2}</style></head><body>')
          html.append(f'<h1>Reporte Dependabot</h1><p>Generado: {ts}</p>')
          html.append('<h2>√çndice</h2><ol><li><a href="#resumen">Resumen general</a></li><li><a href="#dir">M√©tricas por directorio</a></li><li><a href="#eco">M√©tricas por ecosistema</a></li><li><a href="#listado">Listado de PRs</a></li></ol>')
          html.append('<h2 id="resumen">Resumen general</h2>')
          html.append('<table><thead><tr><th>Tipo</th><th>Cantidad</th></tr></thead><tbody>')
          for k in ['major','minor','patch','other']:
              html.append(f'<tr><td>{k}</td><td>{total_agg[k]}</td></tr>')
          html.append('</tbody></table>')
          html.append('<h2 id="dir">M√©tricas por directorio</h2>')
          html.append('<table><thead><tr><th>Directorio</th><th>major</th><th>minor</th><th>patch</th><th>other</th></tr></thead><tbody>')
          for d in sorted(dir_agg.keys()):
              v = dir_agg[d]
              html.append(f'<tr><td>{d}</td><td>{v["major"]}</td><td>{v["minor"]}</td><td>{v["patch"]}</td><td>{v["other"]}</td></tr>')
          html.append('</tbody></table>')
          html.append('<h2 id="eco">M√©tricas por ecosistema</h2>')
          html.append('<table><thead><tr><th>Ecosistema</th><th>major</th><th>minor</th><th>patch</th><th>other</th></tr></thead><tbody>')
          for e in sorted(eco_agg.keys()):
              v = eco_agg[e]
              html.append(f'<tr><td>{e}</td><td>{v["major"]}</td><td>{v["minor"]}</td><td>{v["patch"]}</td><td>{v["other"]}</td></tr>')
          html.append('</tbody></table>')
          html.append('<h2 id="listado">Listado de PRs</h2>')
          html.append('<table><thead><tr><th>PR</th><th>Paquete</th><th>Desde</th><th>Hasta</th><th>Dir</th><th>Estado</th><th>Labels</th><th>Creado</th></tr></thead><tbody>')
          for r in rows:
              html.append(f'<tr><td><a href="{r["url"]}">#{r["num"]}</a></td><td>{r["name"]}</td><td>{r["from"]}</td><td>{r["to"]}</td><td>{r["dir"]}</td><td>{r["state"]}</td><td>{r["labels"]}</td><td>{r["created"]}</td></tr>')
          html.append('</tbody></table>')
          html.append('</body></html>')
          with open(html_path,'w',encoding='utf-8') as f:
              f.write(''.join(html))
          print(f"HTML generado en {html_path}")
          PY

      - name: üì§ Subir HTML del reporte
        if: ${{ inputs.generate_html_report }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-html
          path: docs/${{ inputs.html_report_name }}
      - name: üì§ Subir PDF del reporte
        if: ${{ inputs.generate_pdf_report && steps.generate_pdf.outputs.created == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-pdf
          path: docs/${{ inputs.pdf_report_name }}

      - name: üí¨ Comentar Issue con enlace al PDF
        if: ${{ (inputs.generate_pdf_report || inputs.generate_html_report) && steps.create_issue.outputs.issue_url != '' }}
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          REPO: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
        run: |
          python3 - << 'PY'
          import os, re, subprocess, json
          repo = os.getenv('REPO')
          run_id = os.getenv('RUN_ID')
          issue_url = os.getenv('ISSUE_URL','')
          m = re.search(r"/issues/(\d+)", issue_url)
          if not m:
              raise SystemExit(0)
          num = m.group(1)
          try:
              r = subprocess.run(['gh','api',f'repos/{repo}/actions/runs/{run_id}/artifacts'], capture_output=True, text=True)
              artifacts = json.loads(r.stdout) if r.returncode == 0 else {}
          except Exception:
              artifacts = {}
          server = os.getenv('GITHUB_SERVER_URL','https://github.com')
          run_link = f"{server}/{repo}/actions/runs/{run_id}"
          links = []
          try:
              for a in artifacts.get('artifacts', []):
                  if a.get('name') in ['dependabot-report-pdf','dependabot-report-html']:
                      if 'archive_download_url' in a:
                          links.append(f"{a['name']}: {a['archive_download_url']}")
          except Exception:
              pass
          body = ""
          if links:
              body += "Descargar reportes (zip):\n" + "\n".join(links) + "\n\n"
          body += f"Descargar reportes desde el run: {run_link}\n"
          subprocess.run(['gh','issue','comment',num,'--repo',repo,'--body',body], check=False)
          PY

      - name: üõë Cerrar PRs de Dependabot
        if: ${{ inputs.close_dependabot_prs && steps.detect_prs.outputs.prs_count != '0' && steps.create_issue.outputs.issue_url != '' && !inputs.dry_run_close }}
        env:
          GH_TOKEN: ${{ github.token }}
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          SKIP_CLOSE_LABELS: ${{ inputs.skip_close_labels }}
        run: |
          python3 - << 'PY'
          import json, os, subprocess
          from pathlib import Path
          prs = json.loads(os.getenv('PRS_DATA','[]'))
          closed = 0
          debug_path = Path('docs')/ 'output.txt'
          issue_url = os.getenv('ISSUE_URL','')
          skip_labels = [s.strip().lower() for s in os.getenv('SKIP_CLOSE_LABELS','').split(',') if s.strip()]
          for pr in prs:
              num = pr.get('number')
              if not num:
                  continue
              repo = os.getenv('GITHUB_REPOSITORY')
              labels = [ (l.get('name','') or '').lower() for l in pr.get('labels',[]) ]
              if skip_labels and any(l in skip_labels for l in labels):
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Skipped closing PR #{num} due to labels: {', '.join(labels)}\n")
                  except Exception:
                      pass
                  continue
              comment = 'Cerrado por reporte consolidado de Dependabot'
              if issue_url:
                  comment += f" ‚Äî Reporte: {issue_url}"
              r = subprocess.run(['gh','pr','close',str(num),'--repo',repo,'--delete-branch','--comment',comment], capture_output=True, text=True)
              if r.returncode == 0:
                  closed += 1
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Closed PR #{num}\n")
                  except Exception:
                      pass
              else:
                  try:
                      debug_path.parent.mkdir(parents=True, exist_ok=True)
                      with open(debug_path,'a') as df:
                          df.write(f"Failed to close PR #{num}: {r.stderr.strip()}\n")
                  except Exception:
                      pass
          print(f"üîí PRs cerrados: {closed}")
          PY

      - name: üìä Generate Summary
        env:
          PRS_DATA: ${{ steps.detect_prs.outputs.prs_data }}
          PRS_COUNT: ${{ steps.detect_prs.outputs.prs_count }}
          ISSUE_URL: ${{ steps.create_issue.outputs.issue_url }}
          TRIGGER_DEPENDABOT_NOW: ${{ inputs.trigger_dependabot_now }}
          MAX_SUMMARY: ${{ inputs.max_prs_in_summary }}
          FAST_SUMMARY: ${{ inputs.fast_summary }}
        run: |
          cat > /tmp/generate_summary.py << 'SCRIPT_EOF'
          # Genera el summary del job con tablas, badges y agrupaci√≥n por directorio
          import json, os
          from datetime import datetime, timezone

          repo = os.getenv('GITHUB_REPOSITORY')
          server_url = os.getenv('GITHUB_SERVER_URL', 'https://github.com')

          try:
              prs_raw = os.getenv('PRS_DATA', '[]')
              prs_data = json.loads(prs_raw) if prs_raw and prs_raw.strip() != '' else []
          except Exception as e:
              print(f"::debug::Error parseando PRs: {e}")
              prs_data = []

          prs_count = int(os.getenv('PRS_COUNT', '0'))
          issue_url = os.getenv('ISSUE_URL','')

          def current_state(num: int):
              # Obtiene estado actual del PR (open/merged/closed) si no est√° en modo r√°pido
              try:
                  r = os.popen(f"gh api repos/{repo}/pulls/{num}").read()
                  data = json.loads(r)
                  st = data.get('state','open')
                  merged_at = data.get('merged_at')
                  if st == 'closed' and merged_at:
                      return 'merged'
                  return st
              except Exception:
                  return 'unknown'

          def status_badge(state: str):
              # Genera badge visual para el estado del PR
              color = {'open':'brightgreen','closed':'lightgrey','merged':'purple','unknown':'blue'}.get(state,'blue')
              return f"<img src='https://img.shields.io/badge/status-{state}-{color}?style=flat-square' alt='{state}'/>"

          def label_badges(labels):
              # Genera badges para cada label incluyendo color
              parts = []
              for l in labels:
                  name = l.get('name','')
                  color = l.get('color','0366d6')
                  if not name:
                      continue
                  parts.append(f"<img src='https://img.shields.io/badge/{name.replace('-', '--')}-{color}?style=flat-square' alt='{name}' style='margin:2px'>")
              return ' '.join(parts) if parts else '‚ûñ'

          def days_ago(iso):
              # Calcula edad en d√≠as desde fecha ISO
              try:
                  dt = datetime.fromisoformat(iso.replace('Z', '+00:00'))
                  now = datetime.now(timezone.utc)
                  return (now - dt).days
              except Exception:
                  return None

          def parse_title(t):
              # Extrae paquete/versions/directorio desde t√≠tulo de Dependabot
              import re
              m = re.search(r"bump\s+([^\s]+)\s+from\s+([^\s]+)\s+to\s+([^\s]+)(?:\s+in\s+(.+))?", t, re.IGNORECASE)
              if m:
                  return {'name': m.group(1), 'from': m.group(2), 'to': m.group(3), 'dir': m.group(4) or ''}
              return None

          def semver_tuple(s):
              import re
              parts = re.findall(r"\d+", s)
              nums = [int(x) for x in parts[:3]]
              while len(nums) < 3:
                  nums.append(0)
              return tuple(nums)

          def update_type(f, t):
              # Determina el tipo de actualizaci√≥n a partir de versiones
              fM,fm,fp = semver_tuple(f)
              tM,tm,tp = semver_tuple(t)
              if tM != fM:
                  return 'major'
              if tm != fm:
                  return 'minor'
              if tp != fp:
                  return 'patch'
              return 'other'

          def directory_of(pr):
              meta = parse_title(pr.get('title','')) or {'dir':''}
              d = meta.get('dir','')
              if d:
                  return d
              ref = pr.get('headRefName','')
              if '/' in ref:
                  try:
                      parts = ref.split('/')
                      idx = parts.index('dependabot') if 'dependabot' in parts else -1
                      if idx >= 0 and len(parts) > idx+2:
                          return '/' + '/'.join(parts[idx+2:-1])
                  except Exception:
                      pass
              return '/'

          def sort_key(pr):
              order = {'open':0,'merged':1,'closed':2,'unknown':3}
              st = pr.get('state','open')
              try:
                  ts = datetime.fromisoformat(pr.get('createdAt','').replace('Z','+00:00')).timestamp()
              except Exception:
                  ts = 0
              return (order.get(st,3), -ts)

          summary = []
          summary.append("# üîÑ Pull Requests de Dependabot\n\n")
          if issue_url:
              summary.append(f"> üßæ <b>Reporte consolidado:</b> <a href='{issue_url}'>{issue_url}</a>\n\n")
          if os.getenv('TRIGGER_DEPENDABOT_NOW','false') == 'true':
              cfg_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
              summary.append(f"> ‚ö° <b>Trigger enviado</b>: se edit√≥ <a href='{cfg_url}'>dependabot.yml</a> para forzar un job de actualizaci√≥n.\n\n")

          if prs_data and len(prs_data) > 0:
              try:
                  max_summary = int(os.getenv('MAX_SUMMARY','30'))
              except Exception:
                  max_summary = 30
              prs_sorted = sorted(prs_data, key=sort_key)
              show_list = prs_sorted[:min(prs_count, max_summary)]

              agg = {'major':0,'minor':0,'patch':0,'other':0}
              for pr in show_list:
                  meta = parse_title(pr.get('title',''))
                  if meta and meta['from'] and meta['to']:
                      agg[update_type(meta['from'], meta['to'])] += 1

              summary.append(f"Mostrando {len(show_list)} de {prs_count} PRs\n\n")
              summary.append("<table>\n")
              summary.append("<thead>\n")
              summary.append("<tr>\n")
              summary.append("<th>PR</th><th>Paquete</th><th>Desde</th><th>Hasta</th><th>Dir</th><th>Estado</th><th>Labels</th><th>Edad</th>\n")
              summary.append("</tr>\n")
              summary.append("</thead>\n")
              summary.append("<tbody>\n")
              fast = os.getenv('FAST_SUMMARY','true').lower() == 'true'
              for pr in show_list:
                  pr_number = pr.get('number','N/A')
                  pr_url = pr.get('url','#')
                  pr_title = pr.get('title','Sin t√≠tulo')
                  lbl_html = label_badges(pr.get('labels',[]))
                  created = pr.get('createdAt','')
                  d_ago = days_ago(created)
                  state_now = pr.get('state','open') if fast else current_state(pr_number)
                  meta = parse_title(pr_title) or {'name':'‚Äî','from':'‚Äî','to':'‚Äî','dir':directory_of(pr)}
                  summary.append("<tr>\n")
                  summary.append(f"<td><a href='{pr_url}'><b>#{pr_number}</b></a></td>\n")
                  summary.append(f"<td>{meta['name']}</td>\n")
                  summary.append(f"<td>{meta['from']}</td>\n")
                  summary.append(f"<td>{meta['to']}</td>\n")
                  summary.append(f"<td><code>{meta['dir'] or '/'}</code></td>\n")
                  summary.append(f"<td>{status_badge(state_now)}</td>\n")
                  summary.append(f"<td>{lbl_html}</td>\n")
                  summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                  summary.append("</tr>\n")
              summary.append("</tbody>\n")
              summary.append("</table>\n\n")

              if prs_count > len(show_list):
                  prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+is%3Aopen+author%3Aapp%2Fdependabot"
                  summary.append(f"> <a href='{prs_url}'>üìã <b>Ver todos los PRs ({prs_count})</b></a>\n\n")

              summary.append("<details>\n")
              summary.append("<summary><h2>üìÅ Detalles por directorio</h2></summary>\n\n")
              groups = {}
              for pr in show_list:
                  d = directory_of(pr)
                  groups.setdefault(d or '/', []).append(pr)
              for d in sorted(groups.keys()):
                  items = groups[d]
                  summary.append(f"<h3><code>{d or '/'}</code> ({len(items)})</h3>\n")
                  summary.append("<table>\n<thead>\n<tr>\n<th>PR</th><th>Paquete</th><th>Tipo</th><th>Edad</th>\n</tr>\n</thead>\n<tbody>\n")
                  for pr in items:
                      pr_number = pr.get('number','N/A')
                      pr_url = pr.get('url','#')
                      pr_title = pr.get('title','Sin t√≠tulo')
                      created = pr.get('createdAt','')
                      d_ago = days_ago(created)
                      meta = parse_title(pr_title) or {'name':'‚Äî','from':'','to':''}
                      typ = '‚Äî'
                      if meta['from'] and meta['to']:
                          typ = update_type(meta['from'], meta['to'])
                      typ_badge = f"<img src='https://img.shields.io/badge/update-{typ}-informational?style=flat-square' alt='{typ}'/>"
                      summary.append("<tr>\n")
                      summary.append(f"<td><a href='{pr_url}'>#{pr_number}</a></td>\n")
                      summary.append(f"<td>{meta['name']}</td>\n")
                      summary.append(f"<td>{typ_badge}</td>\n")
                      summary.append(f"<td>{(str(d_ago)+' d') if d_ago is not None else 'N/A'}</td>\n")
                      summary.append("</tr>\n")
                  summary.append("</tbody>\n</table>\n\n")
              summary.append("</details>\n\n")
          else:
              summary.append("> ‚ÑπÔ∏è No hay PRs activos de Dependabot en este momento.\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>‚öôÔ∏è C√≥mo activar manualmente</h2></summary>\n\n")
          dep_graph = f"{server_url}/{repo}/network/dependencies"
          prs_link = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          summary.append("1) Ve a <b>Insights ‚Üí Dependency graph ‚Üí Dependabot</b>\n")
          summary.append(f"2) En <b>Recent update jobs</b>, pulsa <b>Check for updates</b> ‚Ä¢ <a href='{dep_graph}'>Acceder</a>\n")
          summary.append(f"3) Revisa nuevos PRs: <a href='{prs_link}'>Listado de PRs de Dependabot</a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>üìÑ Reportes Exportados</h2></summary>\n\n")
          run_id = os.getenv('GITHUB_RUN_ID','')
          if run_id:
              run_link = f"{server_url}/{repo}/actions/runs/{run_id}"
              summary.append(f"- PDF/HTML: <a href='{run_link}'>Descargar desde el run</a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>üîó Enlaces √ötiles</h2></summary>\n\n")
          config_url = f"{server_url}/{repo}/blob/main/.github/dependabot.yml"
          security_url = f"{server_url}/{repo}/settings/security_analysis"
          insights_url = f"{server_url}/{repo}/network/dependencies"
          labels_url = f"{server_url}/{repo}/labels"
          prs_url = f"{server_url}/{repo}/pulls?q=is%3Apr+author%3Aapp%2Fdependabot"
          advisories_url = f"{server_url}/{repo}/security/dependabot"
          summary.append(f"- üìù <a href='{config_url}'><b>Ver Configuraci√≥n</b></a>\n")
          summary.append(f"- üõ°Ô∏è <a href='{security_url}'><b>Security Settings</b></a>\n")
          summary.append(f"- üìä <a href='{insights_url}'><b>Dependency Graph</b></a>\n")
          summary.append(f"- üè∑Ô∏è <a href='{labels_url}'><b>Gestionar Labels</b></a>\n")
          summary.append(f"- üîÑ <a href='{prs_url}'><b>PRs de Dependabot</b></a>\n")
          summary.append(f"- üö® <a href='{advisories_url}'><b>Security Alerts</b></a>\n\n")
          summary.append("</details>\n\n")

          summary.append("<details>\n")
          summary.append("<summary><h2>‚ÑπÔ∏è Informaci√≥n</h2></summary>\n\n")
          summary.append("- üîç Detecci√≥n y resumen inteligente de PRs\n")
          summary.append("- üè∑Ô∏è Badges de estado y labels\n")
          summary.append("- ‚è±Ô∏è Edad de PRs y ordenamiento\n")
          summary.append("- üìÅ Secci√≥n por directorio\n")
          summary.append("- üîó Enlaces √∫tiles de UI\n\n")
          summary.append("</details>\n\n")

          timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')
          workflow_url = f"{server_url}/jersonmartinez/reusable-workflows"
          summary.append(f"<sub>ü§ñ Generado por <a href='{workflow_url}'><b>Reusable Workflows</b></a> ‚Ä¢ {timestamp}</sub>\n")

          with open(os.environ['GITHUB_STEP_SUMMARY'], 'w') as f:
              f.write(''.join(summary))

          print("‚úÖ Summary generado correctamente")
          print(f"üìä PRs detectados: {prs_count}")
          SCRIPT_EOF

          python3 /tmp/generate_summary.py

      - name: üíæ Subir artifact de depuraci√≥n
        if: ${{ inputs.upload_debug_artifact }}
        uses: actions/upload-artifact@v4
        with:
          name: dependabot-report-debug
          path: docs/output.txt
      fast_summary:
        required: false
        type: boolean
        default: true
        description: 'Acelerar summary evitando llamadas por-PR a la API'
